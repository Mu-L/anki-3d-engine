// Copyright (C) 2009-present, Panagiotis Christopoulos Charitos and contributors.
// All rights reserved.
// Code licensed under the BSD License.
// http://www.anki3d.org/LICENSE

#pragma anki technique Ssr comp
#pragma anki technique RtMaterialFetch rgen miss
#pragma anki technique SpatialDenoise comp
#pragma anki technique TemporalDenoise comp
#pragma anki technique BilateralDenoiseVertical comp
#pragma anki technique BilateralDenoiseHorizontal comp

#include <AnKi/Shaders/RtMaterialFetch.hlsl>
#include <AnKi/Shaders/Include/GpuSceneTypes.h>
#include <AnKi/Shaders/PackFunctions.hlsl>
#include <AnKi/Shaders/LightFunctions.hlsl>
#include <AnKi/Shaders/ImportanceSampling.hlsl>
#include <AnKi/Shaders/BilateralFilter.hlsl>
#include <AnKi/Shaders/SsRaymarching.hlsl>

// Config
constexpr F32 kSpatialUpscalingPcfTexelOffset = 8.0;
#define SPATIAL_UPSCALING_POISON_KERNEL kPoissonDisk4
constexpr F32 kMaxBilateralSamples = 5.0;
constexpr F32 kGaussianSigma = 0.55;

// Functions
Vec3 getDiffuseIndirect(StructuredBuffer<GpuSceneGlobalIlluminationProbe> giProbes, Vec3 worldPos, Vec3 worldNormal,
						SamplerState linearAnyClampSampler)
{
	const U32 probeCount = getStructuredBufferElementCount(giProbes);
	U32 i;
	for(i = 0; i < probeCount; ++i)
	{
		if(all(worldPos < giProbes[i].m_aabbMax) && all(worldPos > giProbes[i].m_aabbMin))
		{
			break;
		}
	}

	const Bool probeFound = (i != probeCount);
	if(probeFound)
	{
		const GpuSceneGlobalIlluminationProbe probe = giProbes[i];
		return sampleGlobalIllumination(worldPos, worldNormal, probe, getBindlessTexture3DRVec4(probe.m_volumeTexture), linearAnyClampSampler);
	}
	else
	{
		return 0.0;
	}
}

// ===========================================================================
// SSR                                                                       =
// ===========================================================================
#if NOT_ZERO(ANKI_TECHNIQUE_Ssr)
#	define EXTRA_REJECTION 1

SamplerState g_trilinearClampSampler : register(s0);

Texture2D<Vec4> g_gbufferRt1 : register(t0);
Texture2D<Vec4> g_gbufferRt2 : register(t1);
Texture2D<Vec4> g_downscaledDepthTex : register(t2);
Texture2D<Vec4> g_depthTex : register(t3);
Texture2D<Vec4> g_lightBufferRt : register(t4);

RWTexture2D<Vec4> g_colorAndPdfTex : register(u0);
RWTexture2D<Vec4> g_hitPosAndDepthTex : register(u1);
RWStructuredBuffer<U32> g_pixelsFailedSsr : register(u2);
RWStructuredBuffer<DispatchIndirectArgs> g_raygenIndirectArgs : register(u3);

ConstantBuffer<GlobalRendererConstants> g_globalRendererConstants : register(b0);

ANKI_FAST_CONSTANTS(SsrConstants2, g_consts)

// All calculations in view space
[NumThreads(8, 8, 1)] void main(UVec2 svDispatchThreadId : SV_DispatchThreadID)
{
	UVec2 outSize;
	g_colorAndPdfTex.GetDimensions(outSize.x, outSize.y);

	const UVec2 coord = min(svDispatchThreadId, outSize - 1u);
	const Vec2 uv = (Vec2(coord) + 0.5) / Vec2(outSize);

	const F32 depth = g_depthTex.SampleLevel(g_trilinearClampSampler, uv, 0.0).x;
	if(depth == 1.0)
	{
		g_colorAndPdfTex[coord] = 0.0;
		g_hitPosAndDepthTex[coord] = 0.0;
		return;
	}

	const Vec4 rt1 = g_gbufferRt1[coord];
	const Vec4 rt2 = g_gbufferRt2[coord];

	const Vec3 worldNormal = unpackNormalFromGBuffer(rt2);
	const Vec3 viewNormal = mul(g_globalRendererConstants.m_matrices.m_view, Vec4(worldNormal, 0.0));
	const F32 roughness = unpackRoughnessFromGBuffer(rt1);

	const Vec2 ndc = uvToNdc(uv);
	const Vec3 viewPos = cheapPerspectiveUnprojection(g_globalRendererConstants.m_matrices.m_unprojectionParameters, ndc, depth);

	// Noise
	const UVec3 seed = rand3DPCG16(UVec3(coord, g_globalRendererConstants.m_frame % 8u));
	const Vec2 randFactors = hammersleyRandom16(g_globalRendererConstants.m_frame % 64u, 64u, seed);

	// Compute refl
	const Vec3 viewDir = -normalize(viewPos);
#	if 1
	F32 pdf;
	const Vec3 reflDir = sampleReflectionVectorIsotropic(viewDir, viewNormal, roughness, randFactors, 4, pdf);
#	else
	ANKI_MAYBE_UNUSED(roughness);
	ANKI_MAYBE_UNUSED(randFactors);
	const Vec3 reflDir = reflect(-viewDir, viewNormal);
	F32 pdf = 1.0;
#	endif

	// Trace
	F32 ssrAttenuation;
	Vec3 hitPoint;
	{
		const U32 lod = 8u; // Use the max LOD for ray marching
		const U32 stepIncrement = g_consts.m_stepIncrement;
		const F32 stepIncrementf = F32(stepIncrement);
		const F32 minStepf = min(4.0f, stepIncrementf);
		const U32 initialStepIncrement = U32(lerp(minStepf, stepIncrementf, randFactors.x));
		F32 hitAttenuation;
		raymarchGroundTruth(viewPos, reflDir, uv, depth, g_consts.m_projMat00_11_22_23, g_consts.m_maxIterations, g_downscaledDepthTex,
							g_trilinearClampSampler, F32(lod), stepIncrement, initialStepIncrement, hitPoint, hitAttenuation);

		ssrAttenuation = hitAttenuation;
	}

	// Compute the hit point in viewspace
	Vec3 hitPointViewSpace = 0.0;
	if(ssrAttenuation > 0.0)
	{
		const F32 depth = g_downscaledDepthTex.SampleLevel(g_trilinearClampSampler, hitPoint.xy, 0.0).r;
		hitPointViewSpace = cheapPerspectiveUnprojection(g_globalRendererConstants.m_matrices.m_unprojectionParameters, uvToNdc(hitPoint.xy), depth);
	}

#	if EXTRA_REJECTION
	// Reject backfacing
	if(ssrAttenuation > 0.0)
	{
		const Vec3 gbufferNormal = unpackNormalFromGBuffer(g_gbufferRt2.SampleLevel(g_trilinearClampSampler, hitPoint.xy, 0.0));
		const Vec3 hitNormal = mul(g_globalRendererConstants.m_matrices.m_view, Vec4(gbufferNormal, 0.0));
		RF32 backFaceAttenuation;
		rejectBackFaces(reflDir, hitNormal, backFaceAttenuation);

		ssrAttenuation *= backFaceAttenuation;
	}

	// Reject far from hit point
	if(ssrAttenuation > 0.0)
	{
		const Vec3 reflRayHitPointVSpace =
			cheapPerspectiveUnprojection(g_globalRendererConstants.m_matrices.m_unprojectionParameters, uvToNdc(hitPoint.xy), hitPoint.z);

		const RF32 rejectionMeters = 0.5f;
		const RF32 diff = length(reflRayHitPointVSpace - hitPointViewSpace);
		const RF32 distAttenuation = 1.0f - smoothstep(0.0f, rejectionMeters, diff);
		ssrAttenuation *= distAttenuation;
	}
#	endif

	// Read the reflection
	Vec3 outColor = 0.0;
	if(ssrAttenuation > 0.0)
	{
		// Reproject the hit point because you are reading the previous frame
		const Vec4 v4 = mul(g_globalRendererConstants.m_matrices.m_reprojection, Vec4(uvToNdc(hitPoint.xy), hitPoint.z, 1.0));
		hitPoint.xy = ndcToUv(v4.xy / v4.w);

		// Read the light buffer
		Vec3 ssrColor = g_lightBufferRt.SampleLevel(g_trilinearClampSampler, hitPoint.xy, 0.0).rgb;
		ssrColor = clamp(ssrColor, 0.0, kMaxRF32); // Fix the value just in case

		outColor = ssrColor;
	}

	// Complete
	if(ssrAttenuation > 0.0)
	{
		// Write to the image

		Vec3 worldHitPos = mul(g_globalRendererConstants.m_matrices.m_cameraTransform, Vec4(hitPointViewSpace, 1.0));
		worldHitPos -= g_globalRendererConstants.m_cameraPosition; // Move it with camera to avoid precision issues since it's stored in fp16

		pdf = max(0.0, pdf) * ssrAttenuation;

		g_colorAndPdfTex[coord] = Vec4(outColor, pdf);
		g_hitPosAndDepthTex[coord] = Vec4(worldHitPos, 1.0 - depth); // Store depth in reverse for better precision
	}
	else
	{
		U32 writePos;
		InterlockedAdd(g_raygenIndirectArgs[0].m_threadGroupCountX, 1u, writePos);

		g_pixelsFailedSsr[writePos] = (coord.x << 16u) | coord.y;
	}
}
#endif

// ===========================================================================
// RayGen                                                                    =
// ===========================================================================
#if ANKI_RAY_GEN_SHADER

struct Consts
{
	F32 m_maxRayT;
	F32 m_padding0;
	F32 m_padding1;
	F32 m_padding2;
};
ANKI_FAST_CONSTANTS(Consts, g_consts)

[shader("raygeneration")] void main()
{
	UVec2 outSize;
	g_colorAndPdfTex.GetDimensions(outSize.x, outSize.y);

	const U32 pixel = g_pixelsFailedSsr[DispatchRaysIndex().x];
	const UVec2 coord = UVec2(pixel >> 16u, pixel & 0xFFFFu);

	const F32 depth = g_depthTex[coord].x;
	if(depth == 1.0)
	{
		g_colorAndPdfTex[coord] = 0.0;
		g_hitPosAndDepthTex[coord] = 0.0;
		return;
	}

	const Vec4 rt1 = g_gbufferRt1[coord];
	const Vec4 rt2 = g_gbufferRt2[coord];

	const Vec3 worldNormal = unpackNormalFromGBuffer(rt2);
	const F32 roughness = unpackRoughnessFromGBuffer(rt1);

	const Vec2 ndc = uvToNdc((Vec2(coord) + 0.5) / Vec2(outSize));
	const Vec4 v4 = mul(g_globalRendererConstants.m_matrices.m_invertedViewProjectionJitter, Vec4(ndc, depth, 1.0));
	const Vec3 worldPos = v4.xyz / v4.w;

	const DirectionalLight dirLight = g_globalRendererConstants.m_directionalLight;

	// Noise
	const UVec3 seed = rand3DPCG16(UVec3(coord, g_globalRendererConstants.m_frame % 8u));
	const Vec2 randFactors = hammersleyRandom16(g_globalRendererConstants.m_frame % 64u, 64u, seed);

	// Compute refl
	const Vec3 viewDir = normalize(g_globalRendererConstants.m_cameraPosition - worldPos);
#	if 1
	F32 pdf;
	const Vec3 reflDir = sampleReflectionVectorIsotropic(viewDir, worldNormal, roughness, randFactors, 4, pdf);
#	else
	ANKI_MAYBE_UNUSED(roughness);
	ANKI_MAYBE_UNUSED(randFactors);
	const Vec3 reflDir = reflect(-viewDir, worldNormal);
	const F32 pdf = 1.0;
#	endif

	// The more rough and the more far this pixel is then instruct the hit shaders to choose less detail mip
	const F32 distanceToMaxMip = 50.0;
	const F32 pixelDistFromCamera = length(worldPos - g_globalRendererConstants.m_cameraPosition);
	const F32 distFactor = pow(pixelDistFromCamera / distanceToMaxMip, 4.0);
	const F32 maxMips = 8.0;
	const F32 textureLod = max(roughness, distFactor) * maxMips;

	// Trace
	RtMaterialFetchRayPayload payload;
	payload = (RtMaterialFetchRayPayload)0;
	payload.m_textureLod = textureLod;

	constexpr U32 flags = RAY_FLAG_FORCE_OPAQUE | RAY_FLAG_SKIP_PROCEDURAL_PRIMITIVES;
	const U32 sbtRecordOffset = 0u;
	const U32 sbtRecordStride = 0u;
	const U32 missIndex = 0u;
	const U32 cullMask = 0xFFu;
	RayDesc ray;
	ray.Origin = worldPos;
	ray.TMin = 0.05;
	ray.Direction = reflDir;
	ray.TMax = g_consts.m_maxRayT;
	TraceRay(g_tlas, flags, cullMask, sbtRecordOffset, sbtRecordStride, missIndex, ray, payload);
	const Bool hasHitSky = payload.m_rayT < 0.0;

	// Trace shadow
	F32 shadow;
	if(!hasHitSky)
	{
		constexpr U32 qFlags = RAY_FLAG_FORCE_OPAQUE | RAY_FLAG_SKIP_PROCEDURAL_PRIMITIVES | RAY_FLAG_ACCEPT_FIRST_HIT_AND_END_SEARCH;
		RayQuery<qFlags> q;
		RayDesc ray;
		ray.Origin = worldPos + reflDir * (payload.m_rayT - 0.01);
		ray.TMin = 0.1;
		ray.Direction = -dirLight.m_direction;
		ray.TMax = g_consts.m_maxRayT;
		q.TraceRayInline(g_tlas, qFlags, cullMask, ray);
		q.Proceed();
		shadow = (q.CommittedStatus() == COMMITTED_TRIANGLE_HIT) ? 0.0 : 1.0;
	}
	else
	{
		// Skybox
		shadow = 1.0;
		payload.m_rayT = g_consts.m_maxRayT;

		const Vec2 uv = octahedronEncode(worldNormal);
		payload.m_emission = g_envMap.SampleLevel(g_linearClampAnySampler, uv, 0.0).xyz;
	}

	// Do simple light shading
	Vec3 outColor = payload.m_emission;

	const Vec3 hitPos = worldPos + reflDir * payload.m_rayT;
	Vec3 indirectDiffuse = 0.0;
	if(!hasHitSky)
	{
		indirectDiffuse = getDiffuseIndirect(g_giProbes, hitPos, payload.m_worldNormal, g_linearClampAnySampler);
	}
	outColor += payload.m_diffuseColor * indirectDiffuse;

	const Vec3 l = -dirLight.m_direction;
	const F32 lambert = dot(l, payload.m_worldNormal);
	const Vec3 diffC = diffuseLobe(payload.m_diffuseColor);
	outColor += diffC * dirLight.m_diffuseColor * lambert * shadow;

	g_colorAndPdfTex[coord] = Vec4(outColor, max(0.0, pdf));

	// Move it with camera to avoid precision issues since it's stored in fp16
	// Store depth in reverse for better precision
	g_hitPosAndDepthTex[coord] = Vec4(hitPos - g_globalRendererConstants.m_cameraPosition, 1.0 - depth);
}
#endif // ANKI_RAY_GEN_SHADER

// ===========================================================================
// Miss                                                                      =
// ===========================================================================
#if ANKI_MISS_SHADER
[shader("miss")] void main(inout RtMaterialFetchRayPayload payload)
{
	payload.m_diffuseColor = 0.0;
	payload.m_worldNormal = 0.0;
	payload.m_emission = 0.0;
	payload.m_rayT = -1.0;
}
#endif // ANKI_MISS_SHADER

// ===========================================================================
// SpatialDenoise                                                            =
// ===========================================================================
#if ANKI_COMPUTE_SHADER && NOT_ZERO(ANKI_TECHNIQUE_SpatialDenoise)
Texture2D<Vec4> g_colorAndPdfTex : register(t0);
Texture2D<Vec4> g_hitPosAndDepthTex : register(t1);
Texture2D<Vec4> g_depthTex : register(t2);
Texture2D<Vec4> g_gbufferRt1 : register(t3);
Texture2D<Vec4> g_gbufferRt2 : register(t4);

RWTexture2D<Vec4> g_denoisedTex : register(u0);
RWTexture2D<Vec4> g_hitPosTex : register(u1);

ConstantBuffer<GlobalRendererConstants> g_globalRendererConstants : register(b0);

#	define NUM_THREADS 64u

[NumThreads(8, 8, 1)] void main(UVec2 svDispatchThreadId : SV_DispatchThreadID, UVec2 svGroupThreadId : SV_GROUPTHREADID,
								U32 svGroupIndex : SV_GROUPINDEX)
{
	UVec2 outSize;
	g_colorAndPdfTex.GetDimensions(outSize.x, outSize.y);

	const UVec2 coord = min(svDispatchThreadId, outSize - 1);

	Vec4 rgba = g_colorAndPdfTex[coord];
	const Vec3 color = rgba.xyz;
	const F32 pdf = rgba.w;

	const F32 depth = g_depthTex[coord];
	if(depth == 1.0)
	{
		g_denoisedTex[svDispatchThreadId] = 0.0;
		return;
	}

	const Vec2 ndc = uvToNdc((Vec2(coord) + 0.5) / Vec2(outSize));
	const Vec4 v4 = mul(g_globalRendererConstants.m_matrices.m_invertedViewProjectionJitter, Vec4(ndc, depth, 1.0));
	const Vec3 worldPos = v4.xyz / v4.w;

	const Vec3 viewDir = normalize(g_globalRendererConstants.m_cameraPosition - worldPos);

	const Vec4 rt1 = g_gbufferRt1[coord];
	const F32 roughness = unpackRoughnessFromGBuffer(rt1);
	const F32 alpha = pow2(roughness);

	Vec3 outColor = 0.0;
	Vec3 newHitPos = 0.0;

	if(roughness <= kMinRoughness + kEpsilonF32)
	{
		outColor = color;
		newHitPos = g_hitPosAndDepthTex[coord].xyz + g_globalRendererConstants.m_cameraPosition;
	}
	else
	{
		const Vec4 rt2 = g_gbufferRt2[coord];
		const Vec3 worldNormal = unpackNormalFromGBuffer(rt2);

		const UVec3 seed = rand3DPCG16(UVec3(svDispatchThreadId, g_globalRendererConstants.m_frame % 8u));
		const Vec2 randFactors = hammersleyRandom16(g_globalRendererConstants.m_frame % 64u, 64u, seed);

		const F32 sinTheta = sin(randFactors.x * 2.0 * kPi);
		const F32 cosTheta = cos(randFactors.x * 2.0 * kPi);

		const F32 sampleCount = ARRAY_SIZE(SPATIAL_UPSCALING_POISON_KERNEL) + 1.0;
		F32 avgLuma = computeLuminance(color) / sampleCount;
		outColor = color;
		F32 weightSum = pdf;
		for(U32 i = 0u; i < ARRAY_SIZE(SPATIAL_UPSCALING_POISON_KERNEL); ++i)
		{
			const Vec2 diskPoint = SPATIAL_UPSCALING_POISON_KERNEL[i];

			// Rotate the disk point
			Vec2 rotatedDiskPoint;
			rotatedDiskPoint.x = diskPoint.x * cosTheta - diskPoint.y * sinTheta;
			rotatedDiskPoint.y = diskPoint.y * cosTheta + diskPoint.x * sinTheta;

			// Offset calculation
			const IVec2 newCoord = clamp(IVec2(coord) + rotatedDiskPoint * kSpatialUpscalingPcfTexelOffset, 0, outSize - 1);

			rgba = g_hitPosAndDepthTex[newCoord];
			const F32 sampleDepth = 1.0 - rgba.w;
			const Vec3 hitPos = rgba.xyz + g_globalRendererConstants.m_cameraPosition;

			const Vec3 reflectedDir = normalize(hitPos - worldPos);
			const F32 pdf = pdfVndfIsotropic(reflectedDir, viewDir, alpha, worldNormal);

			const F32 weight = pdf * calculateBilateralWeightDepth(depth, sampleDepth, 1.0);

			if(weight > 0.001)
			{
				const Vec3 sampleColor = g_colorAndPdfTex[newCoord].xyz;

				outColor += sampleColor * weight;
				weightSum += weight;
				avgLuma += computeLuminance(sampleColor) / sampleCount;

				newHitPos += hitPos * weight;
			}
		}

		outColor /= weightSum;
		newHitPos /= weightSum;

		// Remove fireflies
		const F32 luma = computeLuminance(outColor);
		if(luma > avgLuma && luma > 0.001)
		{
			outColor *= avgLuma / luma;
		}
	}

	g_denoisedTex[coord] = Vec4(outColor, 1.0 - depth); // Store depth in reverse for better precision
	g_hitPosTex[coord] = Vec4(newHitPos - g_globalRendererConstants.m_cameraPosition, 0.0);
}
#endif // ANKI_COMPUTE_SHADER && ANKI_TECHNIQUE_SpatialDenoise

// ===========================================================================
// TemporalDenoise                                                           =
// ===========================================================================
#if ANKI_COMPUTE_SHADER && NOT_ZERO(ANKI_TECHNIQUE_TemporalDenoise)
SamplerState g_linearAnyClampSampler : register(s0);

Texture2D<Vec4> g_colorAndDepth : register(t0);
Texture2D<Vec4> g_historyTex : register(t1);
Texture2D<Vec4> g_momentsHistoryTex : register(t2);
Texture2D<Vec4> g_motionVectorsTex : register(t3);
Texture2D<Vec4> g_hitPosTex : register(t4);

RWTexture2D<Vec4> g_outTex : register(u0);
RWTexture2D<Vec4> g_momentsTex : register(u1);

ConstantBuffer<GlobalRendererConstants> g_globalRendererConstants : register(b0);

// Spacial history UV calculation to decrease parallax reprojection effect
Vec2 computeHistoryUv(UVec2 coords, Vec2 uv)
{
	// Compute the history UV by reprojecting the hit point
	const Vec3 hitWorldPos = g_hitPosTex[coords].xyz + g_globalRendererConstants.m_cameraPosition;

	Vec4 clipPos = mul(g_globalRendererConstants.m_matrices.m_viewProjection, Vec4(hitWorldPos, 1.0));
	clipPos.xy /= clipPos.w;

	Vec4 prevClipPos = mul(g_globalRendererConstants.m_previousMatrices.m_viewProjection, Vec4(hitWorldPos, 1.0));
	prevClipPos.xy /= prevClipPos.w;

	const Vec2 diff = ndcToUv(prevClipPos.xy) - ndcToUv(clipPos.xy);
	const Vec2 hitHistoryUv = uv + diff;

	// Read the motion vectors as well
	const Vec2 motionHistoryUv = uv + g_motionVectorsTex.SampleLevel(g_linearAnyClampSampler, uv, 0.0f).xy;

	// Blend the 2 histories. The more the projected hit point is in the view the more we use it
	F32 factor = max(abs(clipPos.x), abs(clipPos.y));
	factor = min(factor, 1.0);
	factor = pow(factor, 8.0);
	factor = 1 - factor;

	const Vec2 historyUv = lerp(motionHistoryUv, hitHistoryUv, factor);

	return historyUv;
}

void accumulateSourceColor(Vec2 newUv, Vec4 texelWeights, inout Vec3 m1, inout Vec3 m2, inout Vec3 sourceSample, inout Vec3 neighboorMin,
						   inout Vec3 neighboorMax)
{
	const Vec4 red = g_colorAndDepth.GatherRed(g_linearAnyClampSampler, newUv);
	const Vec4 green = g_colorAndDepth.GatherGreen(g_linearAnyClampSampler, newUv);
	const Vec4 blue = g_colorAndDepth.GatherBlue(g_linearAnyClampSampler, newUv);

	[unroll] for(U32 c = 0; c < 4; ++c)
	{
		if(texelWeights[c] > 0.0)
		{
			const Vec3 neighbor = Vec3(red[c], green[c], blue[c]);

			sourceSample += neighbor * texelWeights[c];

			neighboorMin = min(neighboorMin, neighbor);
			neighboorMax = max(neighboorMax, neighbor);

			m1 += neighbor;
			m2 += neighbor * neighbor;
		}
	}
}

void accumulateSourceColor(IVec2 coord, IVec2 textureSize, F32 weight, inout Vec3 m1, inout Vec3 m2, inout Vec3 sourceSample, inout Vec3 neighboorMin,
						   inout Vec3 neighboorMax)
{
	coord = clamp(coord, 0, textureSize - 1);

	const Vec3 neighbor = g_colorAndDepth[coord].xyz;

	sourceSample += neighbor * weight;

	neighboorMin = min(neighboorMin, neighbor);
	neighboorMax = max(neighboorMax, neighbor);

	m1 += neighbor;
	m2 += neighbor * neighbor;
}

void computeSourceColor(Vec2 uv, IVec2 coord, IVec2 textureSize, out Vec3 m1, out Vec3 m2, out Vec3 sourceSample, out Vec3 neighboorMin,
						out Vec3 neighboorMax)
{
	sourceSample = 0.0;
	neighboorMin = 1000.0;
	neighboorMax = -1000.0;
	m1 = 0.0;
	m2 = 0.0;

	const Vec2 texelSize = 1.0 / textureSize;
	const Vec2 halfTexelSize = texelSize / 2.0;

	// Positioning mentioned bellow is in screen space (bottom left is in the bottom left of the screen)
	// Alogithm wants to sample 9 taps of this:
	// +-+-+-+
	// |6|7|8|
	// +-+-+-+
	// |3|4|5|
	// +-+-+-+
	// |0|1|2|
	// +-+-+-+
	// "uv" points to the middle of 4

	// Bottom left (0, 1, 4, 3)
	Vec2 newUv = uv + Vec2(-halfTexelSize.x, +halfTexelSize.y);
	accumulateSourceColor(newUv, Vec4(0.5, 0.5, 1.0, 0.5), m1, m2, sourceSample, neighboorMin, neighboorMax);

	// Top right (4, 5, 8, 7)
	newUv = uv + Vec2(+halfTexelSize.x, -halfTexelSize.y);
	accumulateSourceColor(newUv, Vec4(0.0, 0.5, 0.5, 0.5), m1, m2, sourceSample, neighboorMin, neighboorMax);

	// Top left
	accumulateSourceColor(coord + IVec2(-1, -1), textureSize, 0.5, m1, m2, sourceSample, neighboorMin, neighboorMax);

	// Bottom right
	accumulateSourceColor(coord + IVec2(+1, +1), textureSize, 0.5, m1, m2, sourceSample, neighboorMin, neighboorMax);

	// Misc
	sourceSample /= 1.0 + 0.5 * 8.0;
}

[numthreads(8, 8, 1)] void main(UVec2 svDispatchThreadId : SV_DISPATCHTHREADID)
{
	UVec2 textureSize;
	g_colorAndDepth.GetDimensions(textureSize.x, textureSize.y);

	const UVec2 coord = min(svDispatchThreadId, textureSize - 1);
	const Vec2 uv = (Vec2(coord) + 0.5f) / textureSize;

	// Read crnt
	const F32 depth = g_colorAndDepth[coord].w;
	Vec3 sourceSample = 0.0;
	Vec3 neighboorMin = 0.0;
	Vec3 neighboorMax = 0.0;
	Vec3 m1 = 0.0;
	Vec3 m2 = 0.0;
	computeSourceColor(uv, coord, textureSize, m1, m2, sourceSample, neighboorMin, neighboorMax);

	// Read history
	const Vec2 historyUv = computeHistoryUv(coord, uv);
	Vec3 history = g_historyTex.SampleLevel(g_linearAnyClampSampler, historyUv, 0.0f);

	// Fix history
	constexpr F32 sampleCount = 9.0;
	const F32 gamma = 1.0;
	const Vec3 mu = m1 / sampleCount;
	const Vec3 sigma = sqrt(abs((m2 / sampleCount) - (mu * mu)));
	const Vec3 minc = mu - gamma * sigma;
	const Vec3 maxc = mu + gamma * sigma;

	history = clamp(history, minc, maxc);

	// Blend history and current
	const Vec3 compressedSource = sourceSample * rcp(max3(sourceSample) + 1.0);
	const Vec3 compressedHistory = history * rcp(max3(history) + 1.0);
	const F32 luminanceSource = computeLuminance(compressedSource);
	const F32 luminanceHistory = computeLuminance(compressedHistory);

	F32 sourceWeight = 0.1;
	F32 historyWeight = 1.0 - sourceWeight;
	sourceWeight *= 1.0 / (1.0 + luminanceSource);
	historyWeight *= 1.0 / (1.0 + luminanceHistory);

	const Vec3 finalVal = (sourceSample * sourceWeight + history * historyWeight) / max(sourceWeight + historyWeight, 0.00001);

	// Temporal variance
	const Vec2 momentsHistory = g_momentsHistoryTex.SampleLevel(g_linearAnyClampSampler, historyUv, 0.0f).xy;
	Vec2 crntMoments;
	crntMoments.x = luminanceSource;
	crntMoments.y = crntMoments.x * crntMoments.x;
	const Vec2 moments = lerp(crntMoments, momentsHistory, 0.25);

	// Write value
	g_outTex[coord] = Vec4(finalVal, depth);
	g_momentsTex[coord] = Vec4(moments, 0.0, 0.0);
}
#endif // ANKI_COMPUTE_SHADER && ANKI_TECHNIQUE_TemporalDenoise

// ===========================================================================
// BilateralDenoiseHorizontal                                                =
// ===========================================================================
#if ANKI_COMPUTE_SHADER && NOT_ZERO(ANKI_TECHNIQUE_BilateralDenoiseHorizontal)
Texture2D<Vec4> g_colorAndDepth : register(t0);
Texture2D<Vec4> g_momentsTex : register(t1);
Texture2D<Vec4> g_gbufferRt1 : register(t2);

RWTexture2D<Vec4> g_outTex : register(u0);

F32 computeVarianceCenter(IVec2 coord, UVec2 textureSize)
{
#	if 1
	const F32 kernel[2][2] = {{1.0 / 4.0, 1.0 / 8.0}, {1.0 / 8.0, 1.0 / 16.0}};
	const I32 radius = 1;

	Vec2 sumMoments = 0.0f;
	for(I32 yy = -radius; yy <= radius; yy++)
	{
		for(I32 xx = -radius; xx <= radius; xx++)
		{
			IVec2 newCoord = coord + IVec2(xx, yy);
			newCoord = clamp(newCoord, 0, textureSize - 1);

			const F32 k = kernel[abs(xx)][abs(yy)];
			sumMoments += g_momentsTex[newCoord].xy * k;
		}
	}

	return abs(sumMoments.y - sumMoments.x * sumMoments.x);
#	else
	Vec2 sumMoments = g_momentsTex[coord].xy;
	return abs(sumMoments.y - sumMoments.x * sumMoments.x);
#	endif
}

[NumThreads(8, 8, 1)] void main(UVec2 svDispatchThreadId : SV_DispatchThreadID)
{
	UVec2 outSize;
	g_outTex.GetDimensions(outSize.x, outSize.y);

	const UVec2 coord = min(svDispatchThreadId, outSize - 1);
	Vec4 rgba = g_colorAndDepth[coord];
	const F32 refDepth = rgba.w;
	const Vec3 centerColor = rgba.xyz;

	const F32 variance = sqrt(computeVarianceCenter(coord, outSize)) * 100.0;

	const Vec4 rt1 = g_gbufferRt1[coord];
	const F32 roughness = unpackRoughnessFromGBuffer<F32>(rt1, 0.0);
	const F32 sqRoughness = sqrt(roughness);

	const F32 lerpFactor = sqRoughness * min(1.0, max(sqRoughness, variance));

	const F32 sampleCount = round(lerp(0, kMaxBilateralSamples, lerpFactor));

	F32 weightSum = gaussianWeight2d<F32>(kGaussianSigma, 0.0, 0.0);
	Vec3 colorSum = centerColor * weightSum;
	for(F32 x = -sampleCount; x <= sampleCount; x += 1.0)
	{
		if(x == 0.0)
		{
			continue;
		}

		IVec2 newCoord = coord + IVec2(x, 0);
		newCoord.x = clamp(newCoord.x, 0, outSize.x - 1);

		rgba = g_colorAndDepth[newCoord];
		const F32 sampleDepth = rgba.w;
		const Vec3 sampleColor = rgba.xyz;

		const F32 gWeight = gaussianWeight<F32>(kGaussianSigma, x / sampleCount);
		const F32 depthWeight = calculateBilateralWeightDepth(refDepth, sampleDepth, 1.0);
		const F32 weight = gWeight * depthWeight;

		colorSum += sampleColor * weight;
		weightSum += weight;
	}

	colorSum /= weightSum;

	// Encode the step count in the signs of the out color
	const U32 sampleCountu = sampleCount;
	Vec4 signs;
	[unroll] for(U32 i = 0; i < 4; i++)
	{
		signs[i] = (sampleCountu & (1u << i)) ? 1.0 : -1.0;
	}

	g_outTex[coord] = Vec4(colorSum, refDepth) * signs;
}
#endif // ANKI_COMPUTE_SHADER && ANKI_TECHNIQUE_BilateralDenoiseHorizontal

// ===========================================================================
// BilateralDenoiseVertical                                                  =
// ===========================================================================
#if ANKI_COMPUTE_SHADER && NOT_ZERO(ANKI_TECHNIQUE_BilateralDenoiseVertical)
Texture2D<Vec4> g_colorAndDepthAndSampleCount : register(t0);

RWTexture2D<Vec4> g_outTex : register(u0);
RWStructuredBuffer<DispatchIndirectArgs> g_raygenIndirectArgs : register(u1);

F32 decodeSampleCount(Vec4 rgba)
{
	U32 sampleCountu = 0;
	[unroll] for(U32 i = 0; i < 4; ++i)
	{
		sampleCountu |= (sign(rgba[i]) > 0.0) ? (1u << i) : 0u;
	}

	return sampleCountu;
}

[NumThreads(8, 8, 1)] void main(UVec2 svDispatchThreadId : SV_DispatchThreadID)
{
	UVec2 outSize;
	g_outTex.GetDimensions(outSize.x, outSize.y);

	const UVec2 coord = min(svDispatchThreadId, outSize - 1);

	if(coord.x == 0 && coord.y == 0)
	{
		// Reset the value for the next frame
		g_raygenIndirectArgs[0].m_threadGroupCountX = 0;
	}

	Vec4 rgba = g_colorAndDepthAndSampleCount[coord];
	const F32 sampleCount = decodeSampleCount(rgba);
	rgba = abs(rgba);
	const F32 refDepth = rgba.w;
	const Vec3 refColor = rgba.xyz;

	F32 weightSum = gaussianWeight<F32>(kGaussianSigma, 0.0);
	Vec3 colorSum = refColor * weightSum;
	for(F32 y = -sampleCount; y <= sampleCount; y += 1.0)
	{
		if(y == 0.0)
		{
			continue;
		}

		IVec2 newCoord = coord + IVec2(0.0, y);
		newCoord.y = clamp(newCoord.y, 0, outSize.y - 1);

		rgba = abs(g_colorAndDepthAndSampleCount[newCoord]);
		const F32 sampleDepth = rgba.w;
		const Vec3 sampleColor = rgba.xyz;

		const F32 gWeight = gaussianWeight<F32>(kGaussianSigma, y / sampleCount);
		const F32 depthWeight = calculateBilateralWeightDepth(refDepth, sampleDepth, 1.0);
		const F32 weight = gWeight * depthWeight;

		colorSum += sampleColor * weight;
		weightSum += weight;
	}

	colorSum /= weightSum;

	g_outTex[coord] = Vec4(colorSum, 1.0);
}
#endif // ANKI_COMPUTE_SHADER && ANKI_TECHNIQUE_BilateralDenoiseVertical
