// Copyright (C) 2009-present, Panagiotis Christopoulos Charitos and contributors.
// All rights reserved.
// Code licensed under the BSD License.
// http://www.anki3d.org/LICENSE

// Screen space reflections

#include <AnKi/Shaders/QuadVert.hlsl>

// ===========================================================================
// SSR                                                                       =
// ===========================================================================
#if ANKI_TECHNIQUE_Ssr && (ANKI_COMPUTE_SHADER || ANKI_FRAGMENT_SHADER)
#	include <AnKi/Shaders/Include/MiscRendererTypes.h>
#	include <AnKi/Shaders/Functions.hlsl>
#	include <AnKi/Shaders/PackFunctions.hlsl>
#	include <AnKi/Shaders/FastMathFunctions.hlsl>
#	include <AnKi/Shaders/ImportanceSampling.hlsl>
#	include <AnKi/Shaders/SsRaymarching.hlsl>

#	define EXTRA_REJECTION 1

ConstantBuffer<SsrConstants> g_consts : register(b0);

SamplerState g_trilinearClampSampler : register(s0);
Texture2D<RVec4> g_gbufferRt1 : register(t0);
Texture2D<RVec4> g_gbufferRt2 : register(t1);
Texture2D<Vec4> g_depthRt : register(t2);
Texture2D<RVec4> g_lightBufferRt : register(t3);

#	if ANKI_COMPUTE_SHADER
RWTexture2D<RVec4> g_storageTex : register(u0);
#	endif

#	if ANKI_COMPUTE_SHADER
[numthreads(8, 8, 1)] void main(UVec2 svDispatchThreadId : SV_DISPATCHTHREADID)
#	else
RVec4 main(VertOut input) : SV_TARGET0
#	endif
{
#	if ANKI_COMPUTE_SHADER
	const Vec2 uv = (Vec2(svDispatchThreadId) + 0.5f) / g_consts.m_viewportSizef;
#	else
	const UVec2 svDispatchThreadId = UVec2(input.m_svPosition.xy);
	const Vec2 uv = input.m_uv;
#	endif

	// Read part of the G-buffer
	const RF32 roughness = unpackRoughnessFromGBuffer(g_gbufferRt1.SampleLevel(g_trilinearClampSampler, uv, 0.0));
	const Vec3 worldNormal = unpackNormalFromGBuffer(g_gbufferRt2.SampleLevel(g_trilinearClampSampler, uv, 0.0));

	// Get depth
	const F32 depth = g_depthRt.SampleLevel(g_trilinearClampSampler, uv, 0.0).r;

	// Rand idx
	const RVec2 noise2 = spatioTemporalNoise(svDispatchThreadId, g_consts.m_frameCount);

	// Get view pos
	const Vec3 viewPos = cheapPerspectiveUnprojection(g_consts.m_unprojectionParameters, uvToNdc(uv), depth);

	// Compute refl vector
	const Vec3 viewDir = -normalize(viewPos);
	const Vec3 viewNormal = mul(g_consts.m_normalMat, Vec4(worldNormal, 0.0));
	const Vec3 reflDir = reflect(-viewDir, viewNormal);

	// Is rough enough to deserve SSR?
	RF32 ssrAttenuation = saturate(1.0f - pow(roughness / g_consts.m_roughnessCutoff, 16.0f));

	// Do the heavy work
	Vec3 hitPoint;
	Vec3 hitPointViewSpace;
	if(ssrAttenuation > kEpsilonF32)
	{
		const U32 lod = 8u; // Use the max LOD for ray marching
		const U32 stepIncrement = g_consts.m_stepIncrement;
		const F32 stepIncrementf = F32(stepIncrement);
		const F32 minStepf = min(4.0f, stepIncrementf);
		const U32 initialStepIncrement = U32(lerp(minStepf, stepIncrementf, noise2.x));
		RF32 hitAttenuation;
		raymarchGroundTruth(viewPos, reflDir, uv, depth, g_consts.m_projMat00_11_22_23, g_consts.m_maxIterations, g_depthRt, g_trilinearClampSampler,
							F32(lod), stepIncrement, initialStepIncrement, hitPoint, hitAttenuation);

		ssrAttenuation *= hitAttenuation;

		// Compute the hit point in viewspace
		const F32 depth = g_depthRt.SampleLevel(g_trilinearClampSampler, hitPoint.xy, 0.0).r;
		hitPointViewSpace = cheapPerspectiveUnprojection(g_consts.m_unprojectionParameters, uvToNdc(hitPoint.xy), depth);
	}
	else
	{
		ssrAttenuation = 0.0f;
	}

#	if EXTRA_REJECTION
	// Reject backfacing
	[branch] if(ssrAttenuation > 0.0)
	{
		const Vec3 gbufferNormal = unpackNormalFromGBuffer(g_gbufferRt2.SampleLevel(g_trilinearClampSampler, hitPoint.xy, 0.0));
		const Vec3 hitNormal = mul(g_consts.m_normalMat, Vec4(gbufferNormal, 0.0));
		RF32 backFaceAttenuation;
		rejectBackFaces(reflDir, hitNormal, backFaceAttenuation);

		ssrAttenuation *= backFaceAttenuation;
	}

	// Reject far from hit point
	[branch] if(ssrAttenuation > 0.0)
	{
		const Vec3 reflRayHitPointVSpace = cheapPerspectiveUnprojection(g_consts.m_unprojectionParameters, uvToNdc(hitPoint.xy), hitPoint.z);

		const RF32 rejectionMeters = 0.5f;
		const RF32 diff = length(reflRayHitPointVSpace - hitPointViewSpace);
		const RF32 distAttenuation = 1.0f - smoothstep(0.0f, rejectionMeters, diff);
		ssrAttenuation *= distAttenuation;
	}
#	endif

	// Read the reflection
	RVec3 outColor = 0.0;
	[branch] if(ssrAttenuation > 0.0)
	{
		// Compute the LOD based on the roughness' cone
		Vec2 lightShadingTexSize;
		g_lightBufferRt.GetDimensions(lightShadingTexSize.x, lightShadingTexSize.y);

		const RF32 adjacentLen = length(hitPointViewSpace - viewPos);
		const RF32 coneAngle = pow(roughness - kMinRoughness, 4.0) * kPi / 4.0f; // Not physically correct
		const RF32 oppositeLen = tan(coneAngle / 2.0f) * adjacentLen;
		const Vec3 projectedOpposite =
			cheapPerspectiveProjection(g_consts.m_projMat00_11_22_23, Vec4(hitPointViewSpace + Vec3(oppositeLen, 0.0f, 0.0f), 1.0f));
		const F32 uvDistance = abs(ndcToUv(projectedOpposite.x) - hitPoint.x);
		const RF32 mip = max(0.0f, log2(uvDistance * lightShadingTexSize.x + kEpsilonF32));

		// Reproject the hit point because you are reading the previous frame
		const Vec4 v4 = mul(g_consts.m_prevViewProjMatMulInvViewProjMat, Vec4(uvToNdc(hitPoint.xy), hitPoint.z, 1.0));
		hitPoint.xy = ndcToUv(v4.xy / v4.w);

		// Read the light buffer
		RVec3 ssrColor = g_lightBufferRt.SampleLevel(g_trilinearClampSampler, hitPoint.xy, mip).rgb;
		ssrColor = clamp(ssrColor, 0.0, kMaxRF32); // Fix the value just in case

		outColor = ssrColor;
	}

	// Store
	ssrAttenuation = saturate(ssrAttenuation);
#	if ANKI_COMPUTE_SHADER
	g_storageTex[svDispatchThreadId] = RVec4(outColor, ssrAttenuation);
#	else
	return RVec4(outColor, ssrAttenuation);
#	endif
}

#endif // ANKI_TECHNIQUE_Ssr && (ANKI_COMPUTE_SHADER || ANKI_FRAGMENT_SHADER)

// ===========================================================================
// Techniques                                                                =
// ===========================================================================
#pragma anki technique_start vert Ssr
#pragma anki technique_end vert Ssr

#pragma anki technique_start frag Ssr
#pragma anki technique_end frag Ssr

#pragma anki technique_start comp Ssr
#pragma anki technique_end comp Ssr
