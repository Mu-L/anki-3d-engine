// Copyright (C) 2009-present, Panagiotis Christopoulos Charitos and contributors.
// All rights reserved.
// Code licensed under the BSD License.
// http://www.anki3d.org/LICENSE

#pragma anki 16bit

#pragma anki mutator SSR_SAMPLE_GBUFFER 0 1

#pragma anki technique Classification comp mutators
#pragma anki technique Ssr comp
#pragma anki technique ReflectionProbeFallback comp mutators
#pragma anki technique RtMaterialFetch rgen miss mutators
#pragma anki technique SpatialDenoise comp mutators
#pragma anki technique TemporalDenoise comp mutators
#pragma anki technique BilateralDenoiseVertical comp mutators
#pragma anki technique BilateralDenoiseHorizontal comp mutators

#include <AnKi/Shaders/RtMaterialFetch.hlsl>
#include <AnKi/Shaders/Include/GpuSceneTypes.h>
#include <AnKi/Shaders/PackFunctions.hlsl>
#include <AnKi/Shaders/LightFunctions.hlsl>
#include <AnKi/Shaders/ImportanceSampling.hlsl>
#include <AnKi/Shaders/BilateralFilter.hlsl>
#include <AnKi/Shaders/SsRaymarching.hlsl>
#include <AnKi/Shaders/ClusteredShadingFunctions.hlsl>

// Config & debug
constexpr F32 kSpatialUpscalingPcfTexelOffset = 8.0;
#define SPATIAL_UPSCALING_POISON_KERNEL kPoissonDisk8
constexpr F32 kMaxBilateralSamples = 5.0;
constexpr F32 kGaussianSigma = 0.55;
constexpr Bool kStochasticReflections = true;
constexpr Bool kTryShadowmapFirst = true;
constexpr Bool kDisableDenoising = false;
constexpr F32 kTMinBias = -1.0;
constexpr Bool kExtraSsrRejection = true;
constexpr Bool kDebugSsr = false;
constexpr Bool kSsrHallucinate = true;
constexpr Bool kSsrHallucinateDebug = false;
constexpr F32 kTemporalSourceWeight = 0.01;
constexpr F32 kTemporalGamma = 1.0;
constexpr Bool kPerfectTemporal = true;
#define TILE_SIZE 32

// The states of a tile
enum
{
	kClassNormal, // Always 1st
	kClassSky, // Always 2nd
	kClassMirror,
	kClassVeryRough,
};

// Functions
Vec3 getDiffuseIndirect(StructuredBuffer<GpuSceneGlobalIlluminationProbe> giProbes, Vec3 worldPos, Vec3 worldNormal,
						SamplerState linearAnyClampSampler)
{
	const U32 probeCount = getStructuredBufferElementCount(giProbes);
	U32 i;
	for(i = 0; i < probeCount; ++i)
	{
		if(any(worldPos >= giProbes[i].m_aabbMax) || any(worldPos <= giProbes[i].m_aabbMin))
		{
			continue;
		}
		else
		{
			break;
		}
	}

	const Bool probeFound = (i != probeCount);
	if(probeFound)
	{
		const GpuSceneGlobalIlluminationProbe probe = giProbes[i];
		return sampleGlobalIllumination<F32>(worldPos, worldNormal, probe, getBindlessTexture3DVec4(probe.m_volumeTexture), linearAnyClampSampler);
	}
	else
	{
		return 0.0;
	}
}

HVec4 encodeColorDepthAndSampleCount(HVec3 color, F16 depth, U32 sampleCount)
{
	HVec4 signs;
	[unroll] for(U32 i = 0; i < 4; i++)
	{
		signs[i] = (sampleCount & (1u << i)) ? 1.0 : -1.0;
	}

	return (HVec4(color, depth) + 0.01) * signs; // Add 0.01 to make sure that the sign sticks
}

void decodeColorDepthAndSampleCount(HVec4 rgba, out HVec3 color, out F16 depth, out U32 sampleCount)
{
	sampleCount = 0;
	[unroll] for(U32 i = 0; i < 4; ++i)
	{
		sampleCount |= (sign(rgba[i]) > 0.0) ? (1u << i) : 0u;
	}

	rgba = abs(rgba);
	rgba -= 0.01;

	color = rgba.xyz;
	depth = rgba.w;
}

// ===========================================================================
// Classification                                                            =
// ===========================================================================
#if NOT_ZERO(ANKI_TECHNIQUE_Classification)

SamplerState g_trilinearClampSampler : register(s0);

Texture2D<Vec4> g_gbufferRt1 : register(t0);
Texture2D<Vec4> g_depthTex : register(t1);

RWTexture2D<UVec4> g_classTimeMap : register(u0);

ANKI_FAST_CONSTANTS(ReflectionConstants, g_consts)

groupshared U32 g_minRoughness;
groupshared U32 g_maxRoughness;
groupshared U32 g_allSky;

[NumThreads(TILE_SIZE / 2, TILE_SIZE, 1)] void main(U32 svGroupIndex : SV_GroupIndex, UVec2 svDispatchThreadId : SV_DispatchThreadID,
													UVec2 svGroupId : SV_GroupID)
{
	if(svGroupIndex == 0)
	{
		g_minRoughness = asuint(1.0);
		g_maxRoughness = asuint(0.0);
		g_allSky = 0;
	}

	GroupMemoryBarrierWithGroupSync();

	UVec2 fullViewportSize;
	g_gbufferRt1.GetDimensions(fullViewportSize.x, fullViewportSize.y);

	const UVec2 realCoord = min(svDispatchThreadId, fullViewportSize / UVec2(2, 1) - 1u);
	const UVec2 logicalCoord = UVec2(realCoord.x * 2u + (realCoord.y & 1u), realCoord.y);

	const F32 depth = g_depthTex[logicalCoord].x;

	if(depth < 1.0)
	{
		const Vec4 rt1 = g_gbufferRt1[logicalCoord];
		const F32 roughness = unpackRoughnessFromGBuffer(rt1);

		U32 orig;
		InterlockedMax(g_maxRoughness, asuint(roughness), orig);
		InterlockedMin(g_minRoughness, asuint(roughness), orig);
	}
	else
	{
		InterlockedAdd(g_allSky, 1u);
	}

	GroupMemoryBarrierWithGroupSync();

	if(svGroupIndex == 0)
	{
		U32 tileClass = 0;
		if(g_allSky == TILE_SIZE / 2 * TILE_SIZE)
		{
			tileClass = kClassSky;
		}
		else if(asfloat(g_minRoughness) >= g_consts.m_roughnessCutoffToGiEdges.y && g_allSky == 0)
		{
			tileClass = kClassVeryRough;
		}
		else if(asfloat(g_maxRoughness) <= kMinRoughness * 2.0)
		{
			tileClass = kClassMirror;
		}
		else
		{
			tileClass = kClassNormal;
		}

		g_classTimeMap[svGroupId] = tileClass;
	}
}
#endif

// ===========================================================================
// SSR                                                                       =
// ===========================================================================
#if NOT_ZERO(ANKI_TECHNIQUE_Ssr)
constexpr F32 kLowAttenuation = 0.01;

SamplerState g_trilinearClampSampler : register(s0);
SamplerComparisonState g_shadowSampler : register(s1);

Texture2D<Vec4> g_gbufferRt0 : register(t0);
Texture2D<Vec4> g_gbufferRt1 : register(t1);
Texture2D<Vec4> g_gbufferRt2 : register(t2);
Texture2D<Vec4> g_downscaledDepthTex : register(t3);
Texture2D<Vec4> g_depthTex : register(t4);
Texture2D<Vec4> g_lightBufferRt : register(t5);
StructuredBuffer<GlobalIlluminationProbe> g_giProbes : register(t6);
StructuredBuffer<Cluster> g_clusters : register(t7);
Texture2D<Vec4> g_shadowAtlasTex : register(t8);
Texture2D<UVec4> g_classTileMap : register(t9);

RWTexture2D<Vec4> g_colorAndPdfTex : register(u0);
RWTexture2D<Vec4> g_hitPosAndDepthTex : register(u1);
RWStructuredBuffer<PixelFailedSsr> g_pixelsFailedSsr : register(u2);
RWStructuredBuffer<DispatchIndirectArgs> g_indirectArgs : register(u3);

ConstantBuffer<GlobalRendererConstants> g_globalRendererConstants : register(b0);

ANKI_FAST_CONSTANTS(ReflectionConstants, g_consts)

#	define NUM_THREADS_SQRT 8

groupshared Vec4 g_viewHitPointAndAttenuation[NUM_THREADS_SQRT][NUM_THREADS_SQRT];
groupshared Vec4 g_colorAndDepth[NUM_THREADS_SQRT][NUM_THREADS_SQRT];

Vec3 doLightShading(Vec3 worldPos, Vec3 viewPos, UVec2 coord, F32 depth)
{
	// Read
	GbufferInfo<F32> gbuffer = (GbufferInfo<F32>)0;
	unpackGBufferNoVelocity<F32>(g_gbufferRt0[coord], g_gbufferRt1[coord], g_gbufferRt2[coord], gbuffer);

	Vec3 outColor = gbuffer.m_emission;
	Cluster cluster = getClusterFragCoord(g_clusters, g_globalRendererConstants, Vec3(coord.xy + 0.5, depth));

	// GI
	outColor += sampleGiProbes<F32>(cluster, g_giProbes, gbuffer.m_normal, worldPos.xyz, g_trilinearClampSampler) * gbuffer.m_diffuse;

	// Dir light
	const DirectionalLight dirLight = g_globalRendererConstants.m_directionalLight;
	if(dirLight.m_shadowCascadeCount_31bit_active_1bit & 1u)
	{
		const U32 shadowCascadeCount = dirLight.m_shadowCascadeCount_31bit_active_1bit >> 1u;
		F32 shadowFactor;
		if(shadowCascadeCount >> 1u)
		{
			const F32 negativeZViewSpace = -viewPos.z;

			const U32 cascadeIdx = computeShadowCascadeIndex(negativeZViewSpace, dirLight.m_shadowCascadeDistances, shadowCascadeCount);

			shadowFactor = computeShadowFactorDirLight<F32>(dirLight, cascadeIdx, worldPos, g_shadowAtlasTex, g_shadowSampler);
		}
		else
		{
			shadowFactor = 1.0;
		}

		const Vec3 l = -dirLight.m_direction;
		const F32 lambert = max(0.0, dot(l, gbuffer.m_normal));
		const Vec3 diffC = diffuseLobe(gbuffer.m_diffuse);
		outColor += diffC * dirLight.m_diffuseColor * lambert * shadowFactor;
	}

	return outColor;
}

void doSsr(UVec2 logicalViewportSize, UVec2 realCoord, UVec2 logicalCoord, Vec2 uv, Vec3 viewPos, F32 depth, F32 randFactor, F32 roughness,
		   inout Vec3 viewReflDir, out F32 attenuation, out Vec3 outColor, out Vec3 viewHitPoint)
{
	attenuation = 0.0;
	outColor = 0.0;
	viewHitPoint = 0.0;

	// Trace
	Vec3 hitPoint;
	{
		const U32 lod = 8u; // Use the max LOD for ray marching
		const U32 stepIncrement = g_consts.m_ssrStepIncrement;
		const F32 stepIncrementf = F32(stepIncrement);
		const F32 minStepf = min(4.0f, stepIncrementf);
		const U32 initialStepIncrement = U32(lerp(minStepf, stepIncrementf, randFactor));
		raymarchGroundTruth(viewPos, viewReflDir, uv, depth, g_globalRendererConstants.m_matrices.m_projMat00_11_22_23, g_consts.m_ssrMaxIterations,
							g_downscaledDepthTex, g_trilinearClampSampler, F32(lod), stepIncrement, initialStepIncrement, hitPoint, attenuation);
	}

	if(attenuation < kLowAttenuation)
	{
		viewHitPoint = cheapPerspectiveUnprojection(g_globalRendererConstants.m_matrices.m_unprojectionParameters, uvToNdc(hitPoint.xy), hitPoint.z);
		return;
	}

	const F32 depth1 = g_downscaledDepthTex.SampleLevel(g_trilinearClampSampler, hitPoint.xy, 0.0).r;
	viewHitPoint = cheapPerspectiveUnprojection(g_globalRendererConstants.m_matrices.m_unprojectionParameters, uvToNdc(hitPoint.xy), depth1);

	// Reject backfacing
	if(kExtraSsrRejection)
	{
		const Vec3 gbufferNormal = unpackNormalFromGBuffer(g_gbufferRt2.SampleLevel(g_trilinearClampSampler, hitPoint.xy, 0.0));
		const Vec3 hitNormal = mul(g_globalRendererConstants.m_matrices.m_view, Vec4(gbufferNormal, 0.0));
		F32 backFaceAttenuation;
		rejectBackFaces(viewReflDir, hitNormal, backFaceAttenuation);
		attenuation *= backFaceAttenuation;
		if(attenuation < kLowAttenuation)
		{
			return;
		}
	}

	// Reject far from hit point
	if(kExtraSsrRejection)
	{
		const Vec3 reflRayHitPointVSpace =
			cheapPerspectiveUnprojection(g_globalRendererConstants.m_matrices.m_unprojectionParameters, uvToNdc(hitPoint.xy), hitPoint.z);
		const F32 rejectionMeters = smoothstep(0.1f, 0.6f, roughness);
		const F32 diff = length(reflRayHitPointVSpace - viewHitPoint);
		const F32 distAttenuation = 1.0f - smoothstep(0.0f, rejectionMeters, diff);
		attenuation *= distAttenuation;
		if(attenuation < kLowAttenuation)
		{
			return;
		}
	}

	// Read the reflection
	{
		if(!SSR_SAMPLE_GBUFFER)
		{
			// Reproject the hit point because you are reading the previous frame
			const Vec4 v4 = mul(g_globalRendererConstants.m_matrices.m_reprojection, Vec4(uvToNdc(hitPoint.xy), hitPoint.z, 1.0));
			hitPoint.xy = ndcToUv(v4.xy / v4.w);

			// Read the light buffer
			const Vec3 ssrColor = g_lightBufferRt.SampleLevel(g_trilinearClampSampler, hitPoint.xy, 0.0).rgb;
			outColor = clamp(ssrColor, 0.0, kMaxF32); // Fix the value just in case
		}
		else
		{
			outColor = doLightShading(mul(g_globalRendererConstants.m_matrices.m_cameraTransform, Vec4(viewHitPoint, 1.0)), viewHitPoint,
									  hitPoint.xy * logicalViewportSize, depth1);
		}
	}
}

// Find if a neghbour is closer and we can use it
void bestCandidateToHallucinate(IVec2 svGroupThreadId, IVec2 offset, F32 depth, inout IVec2 neighbourOffset, inout F32 depthWeight,
								inout F32 candidateCount)
{
	const IVec2 svGroupThreadId2 = clamp(svGroupThreadId + offset, 0, NUM_THREADS_SQRT - 1);

	if(g_viewHitPointAndAttenuation[svGroupThreadId2.x][svGroupThreadId2.y].w < kLowAttenuation)
	{
		return;
	}

	candidateCount += 1.0;

	const F32 weight = calculateBilateralWeightDepth<F32>(depth, g_colorAndDepth[svGroupThreadId2.x][svGroupThreadId2.y].w, 1.0);
	if(weight > depthWeight)
	{
		depthWeight = weight;
		neighbourOffset = svGroupThreadId2 - svGroupThreadId;
	}
}

// All calculations in view space
[NumThreads(NUM_THREADS_SQRT, NUM_THREADS_SQRT, 1)] void main(UVec2 svDispatchThreadId : SV_DispatchThreadID,
															  UVec2 svGroupThreadId : SV_GroupThreadID, U32 svGroupIndex : SV_GroupIndex)
{
	UVec2 halfViewportSize;
	g_hitPosAndDepthTex.GetDimensions(halfViewportSize.x, halfViewportSize.y);

	const UVec2 realCoord = min(svDispatchThreadId, halfViewportSize - 1u);
	const UVec2 logicalCoord = UVec2(realCoord.x * 2u + (realCoord.y & 1u), realCoord.y);
	const Vec2 uv = (Vec2(logicalCoord) + 0.5) / Vec2(halfViewportSize.x * 2u, halfViewportSize.y);

	// Fast path 1
	const U32 tileClass = g_classTileMap[logicalCoord / TILE_SIZE];
	if(tileClass == kClassSky)
	{
		g_colorAndPdfTex[realCoord] = 0.0;
		g_hitPosAndDepthTex[realCoord] = 0.0;
		return;
	}

	const F32 depth = g_depthTex[logicalCoord].x;
	const Vec4 rt2 = g_gbufferRt2[logicalCoord];
	const Vec3 worldNormal = unpackNormalFromGBuffer(rt2);

	// Fast path 2
	if(tileClass == kClassVeryRough)
	{
		Vec4 worldPos = mul(g_globalRendererConstants.m_matrices.m_invertedViewProjection, Vec4(uvToNdc(uv), depth, 1.0));
		worldPos.xyz /= worldPos.w;

		const Vec3 reflDir = reflect(normalize(worldPos.xyz - g_globalRendererConstants.m_cameraPosition), worldNormal);

		Cluster cluster = getClusterFragCoord(g_clusters, g_globalRendererConstants, Vec3(logicalCoord.xy + 0.5, depth));

		const Vec3 col = sampleGiProbes<F32>(cluster, g_giProbes, reflDir, worldPos.xyz, g_trilinearClampSampler);

		Vec3 worldHitPos = worldPos + reflDir * 1.0;
		worldHitPos -= g_globalRendererConstants.m_cameraPosition;

		g_colorAndPdfTex[realCoord] = Vec4(col, 1.0);
		g_hitPosAndDepthTex[realCoord] = Vec4(worldHitPos, 1.0 - depth);
		return;
	}

	// Read stuff
	const Vec4 rt1 = g_gbufferRt1[logicalCoord];
	const Vec3 viewNormal = mul(g_globalRendererConstants.m_matrices.m_view, Vec4(worldNormal, 0.0));
	const F32 roughness = unpackRoughnessFromGBuffer(rt1);

	const Vec2 ndc = uvToNdc(uv);
	const Vec3 viewPos = cheapPerspectiveUnprojection(g_globalRendererConstants.m_matrices.m_unprojectionParameters, ndc, depth);

	// Rand
	const UVec3 seed = rand3DPCG16(UVec3(logicalCoord, g_globalRendererConstants.m_frame % 8u));
	const Vec2 randFactors = hammersleyRandom16(g_globalRendererConstants.m_frame % 64u, 64u, seed);

	// Compute refl vector
	const Vec3 viewDir = -normalize(viewPos);

	// Sample GI probes factor
	const F32 sampleGiProbesLerp = smoothstep(g_consts.m_roughnessCutoffToGiEdges.x, g_consts.m_roughnessCutoffToGiEdges.y, roughness);
	const Bool bSampleGiProbes = (sampleGiProbesLerp > randFactors.x); // Choose stocasticly

	// Sample probes or to SS trace
	Vec3 outColor;
	Vec3 viewReflDir;
	Vec3 viewHitPoint;
	F32 pdf;
	F32 ssrAttenuation;
	if(bSampleGiProbes)
	{
		viewReflDir = reflect(-viewDir, viewNormal);

		Cluster cluster = getClusterFragCoord(g_clusters, g_globalRendererConstants, Vec3(logicalCoord.xy + 0.5, depth));

		const Vec3 woldReflDir = mul(g_globalRendererConstants.m_matrices.m_cameraTransform, Vec4(viewReflDir, 0.0));

		Vec4 worldPos = mul(g_globalRendererConstants.m_matrices.m_invertedViewProjection, Vec4(uvToNdc(uv), depth, 1.0));
		worldPos.xyz /= worldPos.w;

		outColor = sampleGiProbes<F32>(cluster, g_giProbes, woldReflDir, worldPos.xyz, g_trilinearClampSampler);

		viewHitPoint = viewPos + viewReflDir * 1.0;
		pdf = 1.0;
		ssrAttenuation = 1.0;
	}
	else
	{
		// SS trace
		if(kStochasticReflections)
		{
			viewReflDir = sampleReflectionVectorIsotropic(viewDir, viewNormal, roughness, randFactors, 4, pdf);
		}
		else
		{
			viewReflDir = reflect(-viewDir, viewNormal);
		}

		doSsr(halfViewportSize * UVec2(2, 1), realCoord, logicalCoord, uv, viewPos, depth, randFactors.x, roughness, viewReflDir, ssrAttenuation,
			  outColor, viewHitPoint);
	}

	// Stash to groupshared
	if(kSsrHallucinate)
	{
		g_viewHitPointAndAttenuation[svGroupThreadId.x][svGroupThreadId.y] = Vec4(viewHitPoint, ssrAttenuation);
		g_colorAndDepth[svGroupThreadId.x][svGroupThreadId.y] = Vec4(outColor, depth);
		GroupMemoryBarrierWithGroupSync();
	}

	if(depth == 1.0)
	{
		// Sky
		g_colorAndPdfTex[realCoord] = 0.0;
		g_hitPosAndDepthTex[realCoord] = 0.0;
		return;
	}

	// Hallucinate if needed
	if(ssrAttenuation <= kLowAttenuation && kSsrHallucinate)
	{
		IVec2 neighbourOffset = -100;
		F32 depthWeight = 0.0;
		F32 candidateCount = 0.0;

		bestCandidateToHallucinate(svGroupThreadId, IVec2(0, -1), depth, neighbourOffset, depthWeight, candidateCount);
		bestCandidateToHallucinate(svGroupThreadId, IVec2(0, 1), depth, neighbourOffset, depthWeight, candidateCount);
		bestCandidateToHallucinate(svGroupThreadId, IVec2(1, -1), depth, neighbourOffset, depthWeight, candidateCount);
		bestCandidateToHallucinate(svGroupThreadId, IVec2(1, 1), depth, neighbourOffset, depthWeight, candidateCount);

		if(neighbourOffset.x != -100 && candidateCount == 4.0)
		{
			// Found something

			const UVec2 neighbourSvGroupThreadId = svGroupThreadId + neighbourOffset;

			viewHitPoint = g_viewHitPointAndAttenuation[neighbourSvGroupThreadId.x][neighbourSvGroupThreadId.y].xyz;

			viewReflDir = normalize(viewHitPoint - viewPos);
			const Vec3 viewDir = normalize(-viewPos);
			const F32 alpha = pow2(roughness);
			pdf = pdfVndfIsotropic(viewReflDir, viewDir, alpha, viewNormal);

			ssrAttenuation = g_viewHitPointAndAttenuation[neighbourSvGroupThreadId.x][neighbourSvGroupThreadId.y].w;

			outColor = g_colorAndDepth[neighbourSvGroupThreadId.x][neighbourSvGroupThreadId.y].xyz;

			if(kSsrHallucinateDebug)
			{
				outColor *= Vec3(0.0, 10.0, 0.0);
			}
		}
	}

	// Complete
	if(ssrAttenuation > kLowAttenuation)
	{
		// Write to the image

		g_colorAndPdfTex[realCoord] = Vec4(outColor, pdf);

		Vec3 worldHitPos = mul(g_globalRendererConstants.m_matrices.m_cameraTransform, Vec4(viewHitPoint, 1.0));
		worldHitPos -= g_globalRendererConstants.m_cameraPosition; // Move it with camera to avoid precision issues since it's stored in fp16

		// Store depth in reverse for better precision
		g_hitPosAndDepthTex[realCoord] = Vec4(worldHitPos, 1.0 - depth);
	}
	else
	{
		if(kDebugSsr)
		{
			g_colorAndPdfTex[realCoord] = Vec4(1.0, 0.0, 1.0, 0.0);
			g_hitPosAndDepthTex[realCoord] = Vec4(1.0, 0.0, 1.0, 0.0);
			return;
		}

		U32 writeOffset;
		InterlockedAdd(g_indirectArgs[0].m_threadGroupCountX, 1u, writeOffset);

		const Vec3 reflDirWorld = mul(g_globalRendererConstants.m_matrices.m_cameraTransform, Vec4(viewReflDir, 0.0)).xyz;

		PixelFailedSsr failedPixel;
		failedPixel.m_pixel = (realCoord.x << 16u) | realCoord.y;
		failedPixel.m_reflectionDirAndRoughness = packSnorm4x8(Vec4(reflDirWorld, roughness));
		failedPixel.m_pdf_f16_rayDirT_f16 = f32tof16(pdf) << 16u;
		failedPixel.m_pdf_f16_rayDirT_f16 |= f32tof16(length(viewPos - viewHitPoint));

		SBUFF(g_pixelsFailedSsr, writeOffset) = failedPixel;

		// Set the threadgroup count for Z for ReflectionProbeFallback
		const U32 failedCount = writeOffset + 1;
		InterlockedMax(g_indirectArgs[1].m_threadGroupCountX, (failedCount + (64 - 1)) / 64);
	}
}
#endif

// ===========================================================================
// ReflectionProbeFallback                                                   =
// ===========================================================================
#if NOT_ZERO(ANKI_TECHNIQUE_ReflectionProbeFallback)

Texture2D<Vec4> g_depthTex : register(t0);
StructuredBuffer<PixelFailedSsr> g_pixelsFailedSsr : register(t1);
StructuredBuffer<ReflectionProbe> g_reflectionProbes : register(t2);
StructuredBuffer<Cluster> g_clusters : register(t3);
StructuredBuffer<U32> g_pixelsFailedSsrCount : register(t4);
Texture2D<Vec4> g_envMap : register(t5);

ConstantBuffer<GlobalRendererConstants> g_globalRendererConstants : register(b0);

SamplerState g_trilinearClampSampler : register(s0);

RWTexture2D<Vec4> g_colorAndPdfTex : register(u0);
RWTexture2D<Vec4> g_hitPosAndDepthTex : register(u1);

[NumThreads(64, 1, 1)] void main(UVec2 svDispatchThreadId : SV_DispatchThreadID)
{
	if(svDispatchThreadId.x >= g_pixelsFailedSsrCount[0])
	{
		return;
	}

	UVec2 viewportSize;
	g_depthTex.GetDimensions(viewportSize.x, viewportSize.y);

	const PixelFailedSsr pixelFailedSsr = g_pixelsFailedSsr[svDispatchThreadId.x];
	const UVec2 realCoord = UVec2(pixelFailedSsr.m_pixel >> 16u, pixelFailedSsr.m_pixel & 0xFFFFu);
	const UVec2 logicalCoord = UVec2(realCoord.x * 2u + (realCoord.y & 1u), realCoord.y);
	const Vec4 packed = unpackSnorm4x8<F32>(pixelFailedSsr.m_reflectionDirAndRoughness);
	const Vec3 reflDir = packed.xyz;
	const F32 roughness = packed.w;
	const F32 pdf = f16tof32(pixelFailedSsr.m_pdf_f16_rayDirT_f16 >> 16u);

	const F32 depth = g_depthTex[logicalCoord].x;
	const Vec2 ndc = uvToNdc((Vec2(logicalCoord) + 0.5) / Vec2(viewportSize));
	const Vec4 v4 = mul(g_globalRendererConstants.m_matrices.m_invertedViewProjectionJitter, Vec4(ndc, depth, 1.0));
	const Vec3 worldPos = v4.xyz / v4.w;

	Cluster cluster = getClusterFragCoord(g_clusters, g_globalRendererConstants, Vec3(logicalCoord.xy + 0.5, depth));

	const F32 reflLod = (g_globalRendererConstants.m_reflectionProbesMipCount - 1.0f) * roughness;
	Vec3 probeColor = sampleReflectionProbes<F32>(cluster, g_reflectionProbes, reflDir, worldPos, reflLod, g_trilinearClampSampler);

	if(probeColor.x < 0.0)
	{
		// No probe, sample sky
		if(g_globalRendererConstants.m_sky.m_type == 0)
		{
			probeColor = g_globalRendererConstants.m_sky.m_solidColor;
		}
		else
		{
			const Vec2 uv = (g_globalRendererConstants.m_sky.m_type == 1) ? equirectangularMapping(reflDir) : octahedronEncode(reflDir);
			probeColor = g_envMap.SampleLevel(g_trilinearClampSampler, uv, 0.0).xyz;
		}
	}

	// Write out
	g_colorAndPdfTex[realCoord] = Vec4(probeColor, max(0.0, pdf));

	// Move it with camera to avoid precision issues since it's stored in fp16
	// Store depth in reverse for better precision
	const Vec3 hitPos = worldPos + reflDir * 100.0; // TODO
	g_hitPosAndDepthTex[realCoord] = Vec4(hitPos - g_globalRendererConstants.m_cameraPosition, 1.0 - depth);
}
#endif

// ===========================================================================
// RayGen                                                                    =
// ===========================================================================
#if ANKI_RAY_GEN_SHADER

struct Consts
{
	F32 m_maxRayT;
	F32 m_padding0;
	F32 m_padding1;
	F32 m_padding2;
};
ANKI_FAST_CONSTANTS(Consts, g_consts)

[shader("raygeneration")] void main()
{
	UVec2 halfViewportSize;
	g_hitPosAndDepthTex.GetDimensions(halfViewportSize.x, halfViewportSize.y);

	const PixelFailedSsr pixelFailedSsr = g_pixelsFailedSsr[DispatchRaysIndex().x];
	const UVec2 realCoord = UVec2(pixelFailedSsr.m_pixel >> 16u, pixelFailedSsr.m_pixel & 0xFFFFu);
	const UVec2 logicalCoord = UVec2(realCoord.x * 2u + (realCoord.y & 1u), realCoord.y);
	const Vec4 packed = unpackSnorm4x8<F32>(pixelFailedSsr.m_reflectionDirAndRoughness);
	const Vec3 reflDir = packed.xyz;
	const F32 roughness = packed.w;
	const F32 pdf = f16tof32(pixelFailedSsr.m_pdf_f16_rayDirT_f16 >> 16u);
	const F32 tmin = f16tof32(pixelFailedSsr.m_pdf_f16_rayDirT_f16 & 0xFFFFu);

	const F32 depth = g_depthTex[logicalCoord].x;
	const Vec2 ndc = uvToNdc((Vec2(logicalCoord) + 0.5) / Vec2(halfViewportSize.x * 2u, halfViewportSize.y));
	const Vec4 v4 = mul(g_globalRendererConstants.m_matrices.m_invertedViewProjectionJitter, Vec4(ndc, depth, 1.0));
	const Vec3 worldPos = v4.xyz / v4.w;

	const DirectionalLight dirLight = g_globalRendererConstants.m_directionalLight;

	// The more rough and the more far this pixel is then instruct the hit shaders to choose less detail mip
	const F32 distanceToMaxMip = 50.0;
	const F32 pixelDistFromCamera = length(worldPos - g_globalRendererConstants.m_cameraPosition);
	const F32 distFactor = pow(pixelDistFromCamera / distanceToMaxMip, 4.0);
	const F32 maxMips = 8.0;
	const F32 textureLod = max(roughness, distFactor) * maxMips;

	// Trace
	RtMaterialFetchRayPayload payload;
	payload = (RtMaterialFetchRayPayload)0;
	payload.m_textureLod = textureLod;

	constexpr U32 flags = RAY_FLAG_FORCE_OPAQUE | RAY_FLAG_SKIP_PROCEDURAL_PRIMITIVES;
	const U32 sbtRecordOffset = 0u;
	const U32 sbtRecordStride = 0u;
	const U32 missIndex = 0u;
	const U32 cullMask = 0xFFu;
	RayDesc ray;
	ray.Origin = worldPos;
	ray.TMin = max(tmin + kTMinBias, 0.05);
	ray.Direction = reflDir;
	ray.TMax = g_consts.m_maxRayT;
	TraceRay(g_tlas, flags, cullMask, sbtRecordOffset, sbtRecordStride, missIndex, ray, payload);

	const Bool hasHitSky = payload.m_rayT < 0.0;
	if(hasHitSky)
	{
		payload.m_rayT = g_consts.m_maxRayT;
	}

	const Vec3 hitPos = worldPos + reflDir * payload.m_rayT;

	// Trace shadow
	Vec4 vv4 = mul(g_globalRendererConstants.m_matrices.m_viewProjection, Vec4(hitPos, 1.0));
	vv4.xy /= vv4.w;
	const Bool bInsideFrustum = all(vv4.xy > -1.0) && all(vv4.xy < 1.0) && vv4.w > 0.0;

	F32 shadow = 0.0;
	if(hasHitSky)
	{
		// Skybox
		shadow = 1.0;

		if(g_globalRendererConstants.m_sky.m_type == 0)
		{
			payload.m_emission = g_globalRendererConstants.m_sky.m_solidColor;
		}
		else
		{
			const Vec2 uv = (g_globalRendererConstants.m_sky.m_type == 1) ? equirectangularMapping(reflDir) : octahedronEncode(reflDir);
			payload.m_emission = g_envMap.SampleLevel(g_linearClampAnySampler, uv, 0.0).xyz;
		}
	}
	else if(bInsideFrustum && kTryShadowmapFirst)
	{
		const F32 negativeZViewSpace = -mul(g_globalRendererConstants.m_matrices.m_view, Vec4(hitPos, 1.0)).z;
		const U32 shadowCascadeCount = dirLight.m_shadowCascadeCount_31bit_active_1bit >> 1u;

		const U32 cascadeIdx = computeShadowCascadeIndex(negativeZViewSpace, dirLight.m_shadowCascadeDistances, shadowCascadeCount);

		shadow = computeShadowFactorDirLight<F32>(dirLight, cascadeIdx, hitPos, g_shadowAtlasTex, g_shadowSampler);
	}
	else
	{
		constexpr U32 qFlags = RAY_FLAG_FORCE_OPAQUE | RAY_FLAG_SKIP_PROCEDURAL_PRIMITIVES | RAY_FLAG_ACCEPT_FIRST_HIT_AND_END_SEARCH;
		RayQuery<qFlags> q;
		RayDesc ray;
		ray.Origin = worldPos + reflDir * (payload.m_rayT - 0.01);
		ray.TMin = 0.1;
		ray.Direction = -dirLight.m_direction;
		ray.TMax = g_consts.m_maxRayT;
		q.TraceRayInline(g_tlas, qFlags, cullMask, ray);
		q.Proceed();
		shadow = (q.CommittedStatus() == COMMITTED_TRIANGLE_HIT) ? 0.0 : 1.0;
	}

	// Do simple light shading
	Vec3 outColor = payload.m_emission;
	Vec3 indirectDiffuse = 0.0;
	if(!hasHitSky)
	{
		indirectDiffuse = getDiffuseIndirect(g_giProbes, hitPos, payload.m_worldNormal, g_linearClampAnySampler);
	}
	outColor += payload.m_diffuseColor * indirectDiffuse;

	const Vec3 l = -dirLight.m_direction;
	const F32 lambert = max(0.0, dot(l, payload.m_worldNormal));
	const Vec3 diffC = diffuseLobe(payload.m_diffuseColor);
	outColor += diffC * dirLight.m_diffuseColor * lambert * shadow;

	g_colorAndPdfTex[realCoord] = Vec4(outColor, max(0.0, pdf));

	// Move it with camera to avoid precision issues since it's stored in fp16
	// Store depth in reverse for better precision
	g_hitPosAndDepthTex[realCoord] = Vec4(hitPos - g_globalRendererConstants.m_cameraPosition, 1.0 - depth);
}
#endif // ANKI_RAY_GEN_SHADER

// ===========================================================================
// Miss                                                                      =
// ===========================================================================
#if ANKI_MISS_SHADER
[shader("miss")] void main(inout RtMaterialFetchRayPayload payload)
{
	payload.m_diffuseColor = 0.0;
	payload.m_worldNormal = 0.0;
	payload.m_emission = 0.0;
	payload.m_rayT = -1.0;
}
#endif // ANKI_MISS_SHADER

// ===========================================================================
// SpatialDenoise                                                            =
// ===========================================================================
#if ANKI_COMPUTE_SHADER && NOT_ZERO(ANKI_TECHNIQUE_SpatialDenoise)
Texture2D<Vec4> g_colorAndPdfTex : register(t0);
Texture2D<Vec4> g_hitPosAndDepthTex : register(t1);
Texture2D<Vec4> g_depthTex : register(t2);
Texture2D<Vec4> g_gbufferRt1 : register(t3);
Texture2D<Vec4> g_gbufferRt2 : register(t4);

RWTexture2D<Vec4> g_denoisedTex : register(u0);
RWTexture2D<Vec4> g_hitPosTex : register(u1);

ConstantBuffer<GlobalRendererConstants> g_globalRendererConstants : register(b0);

ANKI_FAST_CONSTANTS(ReflectionConstants, g_consts)

groupshared Vec4 g_colorAndPdf[8][8];
groupshared Vec4 g_hitPosAndDepth[8][8];

// Return true if the coord contains a pixel that was populated by the previous passes
Bool isCheckerboardWhite(UVec2 coord)
{
	return (coord.y & 1u) == (coord.x & 1u);
}

void reconstructCheckerboardBlack(IVec2 svGroupThreadId, F32 refDepth, inout Vec3 color, inout F32 pdf, inout Vec3 hitPos, inout F32 sumWeight)
{
	if(any(svGroupThreadId < 0u) || any(svGroupThreadId > 7u))
	{
		return;
	}

	const F32 weight = calculateBilateralWeightDepth<F32>(refDepth, g_hitPosAndDepth[svGroupThreadId.x][svGroupThreadId.y].w, 1.0);

	color += g_colorAndPdf[svGroupThreadId.x][svGroupThreadId.y].xyz * weight;
	pdf += g_colorAndPdf[svGroupThreadId.x][svGroupThreadId.y].w * weight;
	hitPos += g_hitPosAndDepth[svGroupThreadId.x][svGroupThreadId.y].xyz * weight;

	sumWeight += weight;
}

[NumThreads(8, 8, 1)] void main(UVec2 svDispatchThreadId : SV_DispatchThreadID, UVec2 svGroupThreadId : SV_GROUPTHREADID,
								U32 svGroupIndex : SV_GROUPINDEX)
{
	UVec2 viewportSize;
	g_colorAndPdfTex.GetDimensions(viewportSize.x, viewportSize.y);
	const UVec2 halfViewportSize = UVec2(viewportSize.x / 2u, viewportSize.y);

	const UVec2 coord = min(svDispatchThreadId, viewportSize - 1u);
	const UVec2 checkerboardCoord = UVec2(coord.x / 2u, coord.y);

	const F32 refDepth = g_depthTex[coord];

	Vec3 refColor = 0.0;
	F32 refPdf = 0.0;
	Vec3 refHitPos = 0.0;
	if(isCheckerboardWhite(coord))
	{
		// Dump pixel data to shared memory to be used to reconstruct other pixels
		const Vec4 rgba = g_colorAndPdfTex[checkerboardCoord];
		refColor = rgba.xyz;
		refPdf = rgba.w;
		g_colorAndPdf[svGroupThreadId.x][svGroupThreadId.y] = rgba;

		refHitPos = g_hitPosAndDepthTex[checkerboardCoord].xyz;
		g_hitPosAndDepth[svGroupThreadId.x][svGroupThreadId.y] = Vec4(refHitPos, refDepth);
	}
	else
	{
		g_colorAndPdf[svGroupThreadId.x][svGroupThreadId.y] = 0.0;
		g_hitPosAndDepth[svGroupThreadId.x][svGroupThreadId.y] = Vec4(0.0, 0.0, 0.0, refDepth);
	}

	GroupMemoryBarrierWithGroupSync();

	if(!isCheckerboardWhite(coord))
	{
		// Reconstruct missing pixel
		const IVec2 svGroupThreadIdi = svGroupThreadId;

		F32 sumWeight = 0.001;
		reconstructCheckerboardBlack(svGroupThreadIdi + IVec2(-1, 0), refDepth, refColor, refPdf, refHitPos, sumWeight);
		reconstructCheckerboardBlack(svGroupThreadIdi + IVec2(+1, 0), refDepth, refColor, refPdf, refHitPos, sumWeight);
		reconstructCheckerboardBlack(svGroupThreadIdi + IVec2(0, +1), refDepth, refColor, refPdf, refHitPos, sumWeight);
		reconstructCheckerboardBlack(svGroupThreadIdi + IVec2(0, -1), refDepth, refColor, refPdf, refHitPos, sumWeight);

		refColor /= sumWeight;
		refPdf /= sumWeight;
		refHitPos /= sumWeight;
	}

	if(refDepth == 1.0)
	{
		g_denoisedTex[coord] = 0.0;
		g_hitPosTex[coord] = 0.0;
		return;
	}

	const Vec4 rt1 = g_gbufferRt1[coord];
	const F32 roughness = unpackRoughnessFromGBuffer(rt1);
	const F32 alpha = pow2(roughness);

	if(kDisableDenoising || roughness >= g_consts.m_roughnessCutoffToGiEdges.y)
	{
		g_denoisedTex[coord] = Vec4(refColor, 1.0 - refDepth); // Store depth in reverse for better precision
		g_hitPosTex[coord] = Vec4(refHitPos - g_globalRendererConstants.m_cameraPosition, 0.0);
		return;
	}

	const Vec2 ndc = uvToNdc((Vec2(coord) + 0.5) / Vec2(viewportSize));
	const Vec4 v4 = mul(g_globalRendererConstants.m_matrices.m_invertedViewProjectionJitter, Vec4(ndc, refDepth, 1.0));
	const Vec3 worldPos = v4.xyz / v4.w;

	const Vec3 viewDir = normalize(g_globalRendererConstants.m_cameraPosition - worldPos);

	Vec3 outColor = 0.0;
	Vec3 newHitPos = 0.0;

	if(roughness <= kMinRoughness + kEpsilonF32)
	{
		outColor = refColor;
		newHitPos = refHitPos + g_globalRendererConstants.m_cameraPosition;
	}
	else
	{
		const Vec4 rt2 = g_gbufferRt2[coord];
		const Vec3 worldNormal = unpackNormalFromGBuffer(rt2);

		const UVec3 seed = rand3DPCG16(UVec3(coord, g_globalRendererConstants.m_frame % 8u));
		const Vec2 randFactors = hammersleyRandom16(g_globalRendererConstants.m_frame % 64u, 64u, seed);

		const F32 sinTheta = sin(randFactors.x * 2.0 * kPi);
		const F32 cosTheta = cos(randFactors.x * 2.0 * kPi);

		const F32 sampleCount = ARRAY_SIZE(SPATIAL_UPSCALING_POISON_KERNEL) + 1.0;
		F32 avgLuma = computeLuminance(refColor) / sampleCount;
		outColor = refColor;
		F32 weightSum = refPdf;
		for(U32 i = 0u; i < ARRAY_SIZE(SPATIAL_UPSCALING_POISON_KERNEL); ++i)
		{
			const Vec2 diskPoint = SPATIAL_UPSCALING_POISON_KERNEL[i];

			// Rotate the disk point
			Vec2 rotatedDiskPoint;
			rotatedDiskPoint.x = diskPoint.x * cosTheta - diskPoint.y * sinTheta;
			rotatedDiskPoint.y = diskPoint.y * cosTheta + diskPoint.x * sinTheta;

			rotatedDiskPoint.x /= 2.0; // Adjust because the input textures are in half width

			// Offset calculation
			const IVec2 newCoord = clamp(IVec2(checkerboardCoord) + rotatedDiskPoint * kSpatialUpscalingPcfTexelOffset, 0, halfViewportSize - 1u);

			const Vec4 rgba = g_hitPosAndDepthTex[newCoord];
			const F32 sampleDepth = 1.0 - rgba.w;
			const Vec3 hitPos = rgba.xyz + g_globalRendererConstants.m_cameraPosition;

			const Vec3 reflectedDir = normalize(hitPos - worldPos);
			const F32 pdf = pdfVndfIsotropic(reflectedDir, viewDir, alpha, worldNormal);

			const F32 weight = pdf * calculateBilateralWeightDepth<F32>(refDepth, sampleDepth, 1.0);

			if(weight > 0.001)
			{
				const Vec3 sampleColor = g_colorAndPdfTex[newCoord].xyz;

				outColor += sampleColor * weight;
				weightSum += weight;
				avgLuma += computeLuminance(sampleColor) / sampleCount;

				newHitPos += hitPos * weight;
			}
		}

		if(weightSum > 0.001)
		{
			outColor /= weightSum;
			newHitPos /= weightSum;
		}
		else
		{
			outColor = 0.0;
			newHitPos = g_globalRendererConstants.m_cameraPosition;
		}

		// Remove fireflies
		const F32 luma = computeLuminance(outColor);
		if(luma > avgLuma && luma > 0.001)
		{
			outColor *= avgLuma / luma;
		}
	}

	g_denoisedTex[coord] = Vec4(outColor, 1.0 - refDepth); // Store depth in reverse for better precision
	g_hitPosTex[coord] = Vec4(newHitPos - g_globalRendererConstants.m_cameraPosition, 0.0);
}
#endif // ANKI_COMPUTE_SHADER && ANKI_TECHNIQUE_SpatialDenoise

// ===========================================================================
// TemporalDenoise                                                           =
// ===========================================================================
#if ANKI_COMPUTE_SHADER && NOT_ZERO(ANKI_TECHNIQUE_TemporalDenoise)
SamplerState g_linearAnyClampSampler : register(s0);

Texture2D<Vec4> g_colorAndDepth : register(t0);
Texture2D<Vec4> g_historyTex : register(t1);
Texture2D<Vec4> g_momentsHistoryTex : register(t2);
Texture2D<Vec4> g_motionVectorsTex : register(t3);
Texture2D<Vec4> g_hitPosTex : register(t4);
Texture2D<UVec4> g_classTileMap : register(t5);

RWTexture2D<Vec4> g_outTex : register(u0);
RWTexture2D<Vec4> g_momentsTex : register(u1);

ConstantBuffer<GlobalRendererConstants> g_globalRendererConstants : register(b0);

// Spacial history UV calculation to decrease parallax reprojection effect
Vec2 computeHistoryUv(UVec2 coords, Vec2 uv)
{
	// Compute the history UV by reprojecting the hit point
	const Vec3 hitWorldPos = g_hitPosTex[coords].xyz + g_globalRendererConstants.m_cameraPosition;

	Vec4 clipPos = mul(g_globalRendererConstants.m_matrices.m_viewProjection, Vec4(hitWorldPos, 1.0));
	clipPos.xy /= clipPos.w;

	Vec4 prevClipPos = mul(g_globalRendererConstants.m_previousMatrices.m_viewProjection, Vec4(hitWorldPos, 1.0));
	prevClipPos.xy /= prevClipPos.w;

	const Vec2 diff = ndcToUv(prevClipPos.xy) - ndcToUv(clipPos.xy);
	const Vec2 hitHistoryUv = uv + diff;

	// Read the motion vectors as well
	const Vec2 motionHistoryUv = uv + g_motionVectorsTex.SampleLevel(g_linearAnyClampSampler, uv, 0.0f).xy;

	// Blend the 2 histories. The more the projected hit point is in the view the more we use it
	F32 factor = max(abs(clipPos.x), abs(clipPos.y));
	factor = min(factor, 1.0);
	factor = pow(factor, 8.0);
	factor = 1 - factor;

	const Vec2 historyUv = lerp(motionHistoryUv, hitHistoryUv, factor);

	return historyUv;
}

void accumulateSourceColor(Vec2 newUv, Vec4 texelWeights, inout Vec3 m1, inout Vec3 m2, inout Vec3 sourceSample, inout Vec3 neighboorMin,
						   inout Vec3 neighboorMax)
{
	const Vec4 red = g_colorAndDepth.GatherRed(g_linearAnyClampSampler, newUv);
	const Vec4 green = g_colorAndDepth.GatherGreen(g_linearAnyClampSampler, newUv);
	const Vec4 blue = g_colorAndDepth.GatherBlue(g_linearAnyClampSampler, newUv);

	[unroll] for(U32 c = 0; c < 4; ++c)
	{
		if(texelWeights[c] > 0.0)
		{
			const Vec3 neighbor = Vec3(red[c], green[c], blue[c]);

			sourceSample += neighbor * texelWeights[c];

			neighboorMin = min(neighboorMin, neighbor);
			neighboorMax = max(neighboorMax, neighbor);

			m1 += neighbor;
			m2 += neighbor * neighbor;
		}
	}
}

void accumulateSourceColor(IVec2 coord, IVec2 textureSize, F32 weight, inout Vec3 m1, inout Vec3 m2, inout Vec3 sourceSample, inout Vec3 neighboorMin,
						   inout Vec3 neighboorMax)
{
	coord = clamp(coord, 0, textureSize - 1);

	const Vec3 neighbor = g_colorAndDepth[coord].xyz;

	sourceSample += neighbor * weight;

	neighboorMin = min(neighboorMin, neighbor);
	neighboorMax = max(neighboorMax, neighbor);

	m1 += neighbor;
	m2 += neighbor * neighbor;
}

void computeSourceColor(Vec2 uv, IVec2 coord, IVec2 textureSize, out Vec3 m1, out Vec3 m2, out Vec3 sourceSample, out Vec3 neighboorMin,
						out Vec3 neighboorMax)
{
	sourceSample = 0.0;
	neighboorMin = 1000.0;
	neighboorMax = -1000.0;
	m1 = 0.0;
	m2 = 0.0;

	const Vec2 texelSize = 1.0 / textureSize;
	const Vec2 halfTexelSize = texelSize / 2.0;

	// Positioning mentioned bellow is in screen space (bottom left is in the bottom left of the screen)
	// Alogithm wants to sample 9 taps of this:
	// +-+-+-+
	// |6|7|8|
	// +-+-+-+
	// |3|4|5|
	// +-+-+-+
	// |0|1|2|
	// +-+-+-+
	// "uv" points to the middle of 4

	// Bottom left (0, 1, 4, 3)
	Vec2 newUv = uv + Vec2(-halfTexelSize.x, +halfTexelSize.y);
	accumulateSourceColor(newUv, Vec4(0.5, 0.5, 1.0, 0.5), m1, m2, sourceSample, neighboorMin, neighboorMax);

	// Top right (4, 5, 8, 7)
	newUv = uv + Vec2(+halfTexelSize.x, -halfTexelSize.y);
	accumulateSourceColor(newUv, Vec4(0.0, 0.5, 0.5, 0.5), m1, m2, sourceSample, neighboorMin, neighboorMax);

	// Top left
	accumulateSourceColor(coord + IVec2(-1, -1), textureSize, 0.5, m1, m2, sourceSample, neighboorMin, neighboorMax);

	// Bottom right
	accumulateSourceColor(coord + IVec2(+1, +1), textureSize, 0.5, m1, m2, sourceSample, neighboorMin, neighboorMax);

	// Misc
	sourceSample /= 1.0 + 0.5 * 8.0;
}

[numthreads(8, 8, 1)] void main(UVec2 svDispatchThreadId : SV_DISPATCHTHREADID)
{
	UVec2 textureSize;
	g_colorAndDepth.GetDimensions(textureSize.x, textureSize.y);

	const UVec2 coord = min(svDispatchThreadId, textureSize - 1);
	const Vec2 uv = (Vec2(coord) + 0.5f) / textureSize;

	const U32 tileClass = g_classTileMap[coord / TILE_SIZE];

	if(kDisableDenoising || tileClass >= kClassSky)
	{
		g_outTex[coord] = g_colorAndDepth[coord];
		g_momentsTex[coord] = 0.0;
		return;
	}

	// Read crnt
	const F32 depth = g_colorAndDepth[coord].w;
	Vec3 sourceSample = 0.0;
	Vec3 neighboorMin = 0.0;
	Vec3 neighboorMax = 0.0;
	Vec3 m1 = 0.0;
	Vec3 m2 = 0.0;
	computeSourceColor(uv, coord, textureSize, m1, m2, sourceSample, neighboorMin, neighboorMax);

	// Read history
	const Vec2 historyUv = computeHistoryUv(coord, uv);
	Vec3 history = g_historyTex.SampleLevel(g_linearAnyClampSampler, historyUv, 0.0f);

	// Fix history
	constexpr F32 sampleCount = 9.0;
	const Vec3 mu = m1 / sampleCount;
	const Vec3 sigma = sqrt(abs((m2 / sampleCount) - (mu * mu)));
	const Vec3 minc = mu - kTemporalGamma * sigma;
	const Vec3 maxc = mu + kTemporalGamma * sigma;

	history = clamp(history, minc, maxc);

	// Blend history and current
	const Vec3 compressedSource = sourceSample * rcp(max3(sourceSample) + 1.0);
	const Vec3 compressedHistory = history * rcp(max3(history) + 1.0);
	const F32 luminanceSource = computeLuminance(compressedSource);
	const F32 luminanceHistory = computeLuminance(compressedHistory);

	F32 sourceWeight = kTemporalSourceWeight;
	F32 historyWeight = 1.0 - sourceWeight;
	sourceWeight *= 1.0 / (1.0 + luminanceSource);
	historyWeight *= 1.0 / (1.0 + luminanceHistory);

	const Vec3 finalVal = (sourceSample * sourceWeight + history * historyWeight) / max(sourceWeight + historyWeight, 0.00001);

	// Temporal variance
	const Vec2 momentsHistory = g_momentsHistoryTex.SampleLevel(g_linearAnyClampSampler, historyUv, 0.0f).xy;
	Vec2 crntMoments;
	crntMoments.x = luminanceSource;
	crntMoments.y = crntMoments.x * crntMoments.x;
	const Vec2 moments = lerp(crntMoments, momentsHistory, 0.25);

	// Write value
	g_outTex[coord] = Vec4(finalVal, depth);
	g_momentsTex[coord] = Vec4(moments, 0.0, 0.0);
}
#endif // ANKI_COMPUTE_SHADER && ANKI_TECHNIQUE_TemporalDenoise

// ===========================================================================
// BilateralDenoiseHorizontal                                                =
// ===========================================================================
#if ANKI_COMPUTE_SHADER && NOT_ZERO(ANKI_TECHNIQUE_BilateralDenoiseHorizontal)
Texture2D<Vec4> g_colorAndDepth : register(t0);
Texture2D<Vec4> g_momentsTex : register(t1);
Texture2D<Vec4> g_gbufferRt1 : register(t2);
Texture2D<UVec4> g_classTileMap : register(t3);

RWTexture2D<Vec4> g_outTex : register(u0);

ANKI_FAST_CONSTANTS(ReflectionConstants, g_consts)

F16 computeVarianceCenter(IVec2 coord, UVec2 textureSize)
{
#	if 1
	const F16 kernel[2][2] = {{1.0 / 4.0, 1.0 / 8.0}, {1.0 / 8.0, 1.0 / 16.0}};
	const I32 radius = 1;

	HVec2 sumMoments = 0.0f;
	for(I32 yy = -radius; yy <= radius; yy++)
	{
		for(I32 xx = -radius; xx <= radius; xx++)
		{
			IVec2 newCoord = coord + IVec2(xx, yy);
			newCoord = clamp(newCoord, 0, textureSize - 1);

			const F16 k = kernel[abs(xx)][abs(yy)];
			sumMoments += g_momentsTex[newCoord].xy * k;
		}
	}

	return abs(sumMoments.y - sumMoments.x * sumMoments.x);
#	else
	Vec2 sumMoments = g_momentsTex[coord].xy;
	return abs(sumMoments.y - sumMoments.x * sumMoments.x);
#	endif
}

[NumThreads(8, 8, 1)] void main(UVec2 svDispatchThreadId : SV_DispatchThreadID)
{
	UVec2 outSize;
	g_outTex.GetDimensions(outSize.x, outSize.y);

	const UVec2 coord = min(svDispatchThreadId, outSize - 1);
	HVec4 rgba = g_colorAndDepth[coord];
	const F16 refDepth = rgba.w;
	const HVec3 centerColor = rgba.xyz;

	const U32 tileClass = g_classTileMap[coord / TILE_SIZE];

	if(kDisableDenoising || tileClass >= kClassSky)
	{
		g_outTex[coord] = encodeColorDepthAndSampleCount(centerColor, refDepth, 0u);
		return;
	}

	const HVec4 rt1 = g_gbufferRt1[coord];
	const F16 roughness = unpackRoughnessFromGBuffer<F16>(rt1, 0.0);
	const F16 sqRoughness = sqrt(roughness);

	if(roughness >= g_consts.m_roughnessCutoffToGiEdges.y)
	{
		g_outTex[coord] = encodeColorDepthAndSampleCount(centerColor, refDepth, 0u);
		return;
	}

	const F16 variance = sqrt(computeVarianceCenter(coord, outSize)) * 100.0;

	const F16 lerpFactor = sqRoughness * min(1.0, max(sqRoughness, variance));

	const F16 sampleCount = round(lerp(0, kMaxBilateralSamples, lerpFactor));

	F16 weightSum = gaussianWeight2d<F16>(kGaussianSigma, 0.0, 0.0);
	HVec3 colorSum = centerColor * weightSum;
	for(F16 x = -sampleCount; x <= sampleCount; x += 1.0)
	{
		if(x == 0.0)
		{
			continue;
		}

		IVec2 newCoord = coord + IVec2(x, 0);
		newCoord.x = clamp(newCoord.x, 0, outSize.x - 1);

		rgba = g_colorAndDepth[newCoord];
		const F16 sampleDepth = rgba.w;
		const HVec3 sampleColor = rgba.xyz;

		const F16 gWeight = gaussianWeight<F16>(kGaussianSigma, x / sampleCount);
		const F16 depthWeight = calculateBilateralWeightDepth<F16>(refDepth, sampleDepth, 1.0);
		const F16 weight = gWeight * depthWeight;

		colorSum += sampleColor * weight;
		weightSum += weight;
	}

	colorSum /= weightSum;

	g_outTex[coord] = encodeColorDepthAndSampleCount(colorSum, refDepth, sampleCount);
}
#endif // ANKI_COMPUTE_SHADER && ANKI_TECHNIQUE_BilateralDenoiseHorizontal

// ===========================================================================
// BilateralDenoiseVertical                                                  =
// ===========================================================================
#if ANKI_COMPUTE_SHADER && NOT_ZERO(ANKI_TECHNIQUE_BilateralDenoiseVertical)
Texture2D<Vec4> g_colorAndDepthAndSampleCount : register(t0);
Texture2D<UVec4> g_classTileMap : register(t1);

RWTexture2D<Vec4> g_outTex : register(u0);
RWStructuredBuffer<DispatchIndirectArgs> g_indirectArgs : register(u1);

[NumThreads(8, 8, 1)] void main(UVec2 svDispatchThreadId : SV_DispatchThreadID)
{
	UVec2 outSize;
	g_outTex.GetDimensions(outSize.x, outSize.y);

	const UVec2 coord = min(svDispatchThreadId, outSize - 1);

	if(coord.x == 0 && coord.y == 0)
	{
		// Reset the value for the next frame
		g_indirectArgs[0].m_threadGroupCountX = 0;
		g_indirectArgs[1].m_threadGroupCountX = 0;
	}

	U32 sampleCountu;
	F16 refDepth;
	HVec3 refColor;
	decodeColorDepthAndSampleCount(g_colorAndDepthAndSampleCount[coord], refColor, refDepth, sampleCountu);
	const F16 sampleCount = sampleCountu;

	const U32 tileClass = g_classTileMap[coord / TILE_SIZE];

	if(kDisableDenoising || tileClass >= kClassSky)
	{
		g_outTex[coord] = HVec4(refColor, 1.0);
		return;
	}

	F16 weightSum = gaussianWeight<F16>(kGaussianSigma, 0.0);
	HVec3 colorSum = refColor * weightSum;
	for(F16 y = -sampleCount; y <= sampleCount; y += 1.0)
	{
		if(y == 0.0)
		{
			continue;
		}

		IVec2 newCoord = coord + IVec2(0.0, y);
		newCoord.y = clamp(newCoord.y, 0, outSize.y - 1);

		F16 sampleDepth;
		HVec3 sampleColor;
		U32 unused;
		decodeColorDepthAndSampleCount(g_colorAndDepthAndSampleCount[newCoord], sampleColor, sampleDepth, unused);

		const F16 gWeight = gaussianWeight<F16>(kGaussianSigma, y / sampleCount);
		const F16 depthWeight = calculateBilateralWeightDepth<F16>(refDepth, sampleDepth, 1.0);
		const F16 weight = gWeight * depthWeight;

		colorSum += sampleColor * weight;
		weightSum += weight;
	}

	colorSum /= weightSum;

	g_outTex[coord] = HVec4(colorSum, 1.0);
}
#endif // ANKI_COMPUTE_SHADER && ANKI_TECHNIQUE_BilateralDenoiseVertical
